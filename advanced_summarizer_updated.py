from openai import OpenAI
import os
from typing import List, Dict, Any, Optional, Tuple, Callable
from dotenv import load_dotenv
import json
import time
import re
import concurrent.futures
from functools import lru_cache
import threading
import random

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# API í˜¸ì¶œ ê´€ë ¨ ì„¤ì •
MAX_RETRIES = 3
BASE_RETRY_DELAY = 1  # ì´ˆ ë‹¨ìœ„
MAX_WORKERS = 3  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜

# API í˜¸ì¶œ ì„¸ë§ˆí¬ì–´ ì¶”ê°€
api_semaphore = threading.Semaphore(3)  # ìµœëŒ€ 3ê°œ ë™ì‹œ ìš”ì²­

def api_call_with_retry(func: Callable, *args, **kwargs) -> Any:
    """
    API í˜¸ì¶œ í•¨ìˆ˜ë¥¼ ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ ê°ì‹¸ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    ì§€ìˆ˜ ë°±ì˜¤í”„ ì „ëµ ì‚¬ìš©
    
    Args:
        func: í˜¸ì¶œí•  í•¨ìˆ˜
        *args, **kwargs: í•¨ìˆ˜ì— ì „ë‹¬í•  ì¸ìë“¤
        
    Returns:
        í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼
    """
    with api_semaphore:
        for attempt in range(MAX_RETRIES):
            try:
                # ì²« ë²ˆì§¸ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€
                if attempt > 0:
                    # ì§€ìˆ˜ ë°±ì˜¤í”„ + ë¬´ì‘ìœ„ì„±(jitter) ì¶”ê°€
                    base_delay = BASE_RETRY_DELAY * (2 ** attempt)
                    jitter = random.uniform(0, 0.5 * base_delay)
                    delay = base_delay + jitter
                    print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ ({attempt+1}/{MAX_RETRIES}), {delay:.2f}ì´ˆ í›„ ì¬ì‹œë„")
                    time.sleep(delay)
                
                return func(*args, **kwargs)
            except Exception as e:
                if attempt == MAX_RETRIES - 1:
                    # ë§ˆì§€ë§‰ ì‹œë„ì˜€ë‹¤ë©´ ì˜ˆì™¸ ë°œìƒ
                    raise
                
                print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ ({attempt+1}/{MAX_RETRIES}): {str(e)}")

def advanced_summarize_texts(texts: List[str], topic: str, structure: str, style: str = "international_relations_expert", output_dir: str = "output_analysis", additional_instructions: str = "", content_types: List[str] = ["longform", "shortform1", "shortform2"]) -> Dict[str, str]:
    """
    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í†µí•© ìš”ì•½í•˜ê³ , ì£¼ì œì™€ ë…¼ë¦¬ êµ¬ì¡°ì— ë§ëŠ” ì½˜í…ì¸  ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    í–¥ìƒëœ ë²„ì „: êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ ê´€ì  ê°•í™”, í•œêµ­ì–´ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
    ë³‘ë ¬ ì²˜ë¦¬ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”
    ë¡±í¼ ë° ìˆí¼ ì½˜í…ì¸  ìƒì„±
    
    Args:
        texts: íŒŒì‹±ëœ ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        topic: ì½˜í…ì¸  ì£¼ì œ
        structure: ë…¼ë¦¬ êµ¬ì¡° (ì˜ˆ: "ì„œë¡ -ë³¸ë¡ -ê²°ë¡ ")
        style: ìŠ¤í¬ë¦½íŠ¸ ìŠ¤íƒ€ì¼ (international_relations_expertë¡œ ê³ ì •)
        output_dir: ì¤‘ê°„ ë¶„ì„ ê²°ê³¼ë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬
        additional_instructions: ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±ì— ëŒ€í•œ ì¶”ê°€ ì§€ì‹œì‚¬í•­
        content_types: ìƒì„±í•  ì½˜í…ì¸  ìœ í˜• ë¦¬ìŠ¤íŠ¸ (ë¡±í¼, ìˆí¼1, ìˆí¼2, ìˆí¼3)
        
    Returns:
        ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ ë”•ì…”ë„ˆë¦¬ {'longform': ë¡±í¼ìŠ¤í¬ë¦½íŠ¸, 'shortform1': ìˆí¼ìŠ¤í¬ë¦½íŠ¸1, 'shortform2': ìˆí¼ìŠ¤í¬ë¦½íŠ¸2, ...}
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    if not texts:
        print("âš ï¸ ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {content_type: "" for content_type in content_types}
    
    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return {content_type: "" for content_type in content_types}
    
    print(f"ğŸ“Š ì´ {len(texts)}ê°œ ì†ŒìŠ¤ ë¶„ì„ ì¤‘...")
    
    # 1. ê° ì†ŒìŠ¤ë³„ êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ ê´€ì  ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬)
    source_summaries = analyze_sources_parallel(texts, topic, output_dir)
    
    # ë¶„ì„ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì¢…ë£Œ
    if len(source_summaries) == 0:
        print("âŒ ëª¨ë“  ì†ŒìŠ¤ ë¶„ì„ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return {content_type: "" for content_type in content_types}
    
    print("âœ… ê°œë³„ ì†ŒìŠ¤ êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ë¶„ì„ ì™„ë£Œ")
    
    # 2. êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ ê´€ì ì˜ í†µí•© ë¶„ì„
    print("ğŸ”„ êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ì†ŒìŠ¤ ê°„ í†µí•© ë¶„ì„ ì¤‘...")
    integrated_analysis = create_integrated_analysis(source_summaries, topic, structure, output_dir)
    
    if not integrated_analysis:
        print("âŒ í†µí•© ë¶„ì„ ìƒì„± ì‹¤íŒ¨")
        # ì‹¤íŒ¨í•œ ê²½ìš° ê°„ë‹¨í•œ ëŒ€ì²´ í†µí•© ë¶„ì„ ìƒì„±
        integrated_analysis = create_fallback_integrated_analysis(source_summaries)
    
    # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    result = {content_type: "" for content_type in content_types}
    
    # 3. ì„ íƒì  ì½˜í…ì¸  ìƒì„±
    if "longform" in content_types:
        # ë¡±í¼ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        print("ğŸ“ êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ ìŠ¤íƒ€ì¼ì˜ ë¡±í¼ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
        result["longform"] = create_longform_script(integrated_analysis, topic, structure, additional_instructions, output_dir)
    
    # ìˆí¼ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    shortform_indices = [int(content_type.replace("shortform", "")) for content_type in content_types if content_type.startswith("shortform")]
    
    for idx in shortform_indices:
        print(f"ğŸ“ ìˆí¼ ìŠ¤í¬ë¦½íŠ¸ #{idx} ìƒì„± ì¤‘...")
        result[f"shortform{idx}"] = create_shortform_script(integrated_analysis, topic, idx, output_dir)
    
    print("âœ… ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ")
    return result

def analyze_sources_parallel(texts: List[str], topic: str, output_dir: str) -> List[Dict[str, Any]]:
    """
    ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì†ŒìŠ¤ë¥¼ ë¶„ì„
    
    Args:
        texts: íŒŒì‹±ëœ ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        topic: ì½˜í…ì¸  ì£¼ì œ
        output_dir: ê²°ê³¼ë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ê° ì†ŒìŠ¤ì˜ ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    source_summaries = []
    
    # í…ìŠ¤íŠ¸ê°€ ë¹ˆ ê²½ìš° ê±´ë„ˆë›°ëŠ” í•„í„°ë§
    valid_texts = [(i, text) for i, text in enumerate(texts) if text.strip()]
    
    if not valid_texts:
        print("âš ï¸ ë¶„ì„í•  ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []

    # ì‘ì—…ëŸ‰ì— ë”°ë¼ ì›Œì»¤ ìˆ˜ ë™ì  ì¡°ì •
    worker_count = min(MAX_WORKERS, len(valid_texts))
    
    # ë§ì€ í…ìŠ¤íŠ¸ë‚˜ í° í…ìŠ¤íŠ¸ì¸ ê²½ìš° ì›Œì»¤ ìˆ˜ ê°ì†Œ
    if len(valid_texts) > 5 or any(len(text) > 10000 for _, text in valid_texts):
        worker_count = max(1, worker_count - 1)
    
    print(f"ğŸ“Š ì´ {len(valid_texts)}ê°œ ì†ŒìŠ¤ ë¶„ì„ ì¤‘... (ì›Œì»¤: {worker_count}ê°œ)")

    # ë¶„ì„ í•¨ìˆ˜ ì •ì˜
    def analyze_source(index_text_tuple: Tuple[int, str]) -> Dict[str, Any]:
        index, text = index_text_tuple
        try:
            print(f"ğŸ“ ì†ŒìŠ¤ #{index+1} êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ ê´€ì  ë¶„ì„ ì¤‘...")
            
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸´ ê²½ìš° ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
            max_chars = 15000  # ì•½ 15,000ì ì œí•œ
            truncated_text = text[:max_chars] if len(text) > max_chars else text
            if len(text) > max_chars:
                truncated_text += "\n\n[í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ì–´ ë‚˜ë¨¸ì§€ëŠ” ìƒëµë˜ì—ˆìŠµë‹ˆë‹¤]"
                
            summary_prompt = f"""
ë‹¹ì‹ ì€ êµ­ì œê´€ê³„, ì§€ì •í•™, ì„¸ê³„ì‚¬ ë¶„ì•¼ì˜ ìµœê³  ì „ë¬¸ê°€ë¡œ, ì†ŒìŠ¤ ë‚´ìš©ì„ êµ­ì œì •ì¹˜ ë° ì—­ì‚¬ì  ê´€ì ì—ì„œ ë¶„ì„í•©ë‹ˆë‹¤.

ì†ŒìŠ¤ #{index+1}ì— ëŒ€í•œ ì‹¬ì¸µ êµ­ì œì •ì¹˜/ì§€ì •í•™/ì„¸ê³„ì‚¬ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. ì£¼ì œëŠ” "{topic}"ì…ë‹ˆë‹¤.
ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

1. êµ­ì œì •ì¹˜ì  í•µì‹¬ ìš”ì ê³¼ ì§€ì •í•™ì  ì˜ë¯¸ (ê°€ëŠ¥í•œ ë§ì€ êµ¬ì²´ì  ì •ë³´ ì¶”ì¶œ)
   - ê´€ë ¨ êµ­ê°€ ë° ì£¼ìš” í–‰ìœ„ì 
   - êµ­ì œê´€ê³„ ë° ì„¸ë ¥ ê· í˜•ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
   - ì§€ì—­ ë° ê¸€ë¡œë²Œ ì•ˆë³´ êµ¬ì¡°ì™€ì˜ ì—°ê´€ì„±
   - ê´€ë ¨ëœ êµ­ì œê¸°êµ¬ ë° ë‹¤ìí˜‘ë ¥ì²´

2. í•´ë‹¹ ì‚¬ì•ˆì˜ ì—­ì‚¬ì  ë§¥ë½ê³¼ ë°°ê²½ (3-5ê°œ ìš”ì )
   - ìœ ì‚¬í•œ ì—­ì‚¬ì  ì„ ë¡€ì™€ ë¹„êµ
   - ì‹œê°„ì  íë¦„ê³¼ ì „ê°œ ê³¼ì •
   - í˜„ëŒ€ êµ­ì œê´€ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
   - ê´€ë ¨ ì¡°ì•½, í˜‘ì •, êµ­ì œë²•ì  ì¸¡ë©´

3. ì§€ì •í•™ì  í•¨ì˜ ë° ì „ëµì  ì¤‘ìš”ì„±
   - ê´€ë ¨ ì§€ì—­ì˜ ì§€ë¦¬ì  íŠ¹ì„±ê³¼ ì˜ë¯¸
   - ìì›, ì—ë„ˆì§€, í•´ìƒ êµí†µë¡œ ë“± ì§€ì •í•™ì  ìš”ì†Œ
   - ì§€ì—­ ë‚´ ì„¸ë ¥ ê²½ìŸê³¼ íŒ¨ê¶Œ êµ¬ë„
   - êµ°ì‚¬ì „ëµì  ì˜ë¯¸ ë° ì•ˆë³´ í•¨ì˜

4. ì£¼ìš” ê´€ë ¨êµ­ë“¤ì˜ ì´í•´ê´€ê³„ì™€ ì •ì±…ì  ì…ì¥
   - ì£¼ìš”êµ­ ì™¸êµì •ì±… ë° ì „ëµ ë¶„ì„
   - êµ­ê°€ ê°„ í˜‘ë ¥ê³¼ ê°ˆë“± ê´€ê³„
   - êµ­ë‚´ì •ì¹˜ì™€ ì™¸êµì •ì±…ì˜ ì—°ê´€ì„±
   - ì£¼ìš” ì •ì±…ê²°ì •ìë“¤ì˜ ê´€ì ê³¼ ì ‘ê·¼ë²•

5. ë‹¤ì–‘í•œ ê´€ì ê³¼ ì´ë¡ ì  ë¶„ì„í‹€ ì ìš©
   - í˜„ì‹¤ì£¼ì˜, ììœ ì£¼ì˜, êµ¬ì„±ì£¼ì˜ ë“± IR ì´ë¡  ê´€ì 
   - ì§€ì •í•™ì  ë¶„ì„ ëª¨ë¸ ì ìš© (ì˜ˆ: ë§¤í‚¨ë”, ìŠ¤íŒŒì´í¬ë¨¼ ì´ë¡ )
   - ì„¸ê³„ì²´ì œë¡ , ì§€ì—­ ì•ˆë³´ ë³µí•©ì²´ ë“± ê±°ì‹œì  ë¶„ì„
   - ì§€ì—­ í†µí•©ê³¼ ë¶„ì—´ì˜ ì—­í•™ ê´€ê³„

6. ë¯¸ë˜ ì „ë§ ë° ì •ì±…ì  í•¨ì˜
   - ë‹¨ê¸° ë° ì¤‘ì¥ê¸° ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
   - ì ì¬ì  ìœ„ê¸°ì™€ ê¸°íšŒ ìš”ì¸
   - ì£¼ìš” ë³€ìˆ˜ì™€ ë¶ˆí™•ì‹¤ì„± ì§€ì 
   - ì£¼ìš” í–‰ìœ„ìë“¤ì˜ ì •ì±…ì˜µì…˜ê³¼ ì „ëµì  ì„ íƒì§€

7. êµ­ì œì •ì¹˜/ì§€ì •í•™ì  ê´€ì ì—ì„œì˜ ê°€ì¹˜ í‰ê°€ (1-5ì , ì „ë¬¸ê°€ ê´€ì  í‰ê°€)
   - êµ­ì œì§ˆì„œì— ëŒ€í•œ ì¤‘ìš”ì„±ê³¼ ì˜í–¥ë ¥
   - ì§€ì—­ ì•ˆì •ê³¼ í‰í™”ì— ëŒ€í•œ í•¨ì˜
   - êµ­ì œë²•ì , ê·œë²”ì  ì¤‘ìš”ì„±
   - ì„¸ê³„ì‚¬ì  ì˜ë¯¸ì™€ ì¤‘ìš”ë„

8. ë‹¤ìŒ ìš”ì†Œë“¤ì´ ìˆë‹¤ë©´ íŠ¹ë³„íˆ ì •ë¦¬í•˜ì„¸ìš”:
   - ê´€ë ¨ êµ­ì œíšŒì˜, ì •ìƒíšŒë‹´, í˜‘ìƒ ê³¼ì •
   - ì£¼ìš” êµ­ì œì¡°ì•½ê³¼ í˜‘ì • ë‚´ìš©
   - ì§€ì •í•™ì  ë³€í™”ë¥¼ ìœ ë°œí•œ ì£¼ìš” ì‚¬ê±´ë“¤
   - êµ­ì œê´€ê³„ ë³€í™”ì˜ í•µì‹¬ ì „í™˜ì ë“¤

ì†ŒìŠ¤ ë‚´ìš©:
{truncated_text}
"""
            # OpenAI API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            def make_api_call():
                res = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": summary_prompt}],
                    temperature=0.3,
                )
                return res.choices[0].message.content.strip()
            
            analysis = api_call_with_retry(make_api_call)
            
            # ë¶„ì„ ê²°ê³¼ ì €ì¥
            source_file = os.path.join(output_dir, f"source_{index+1}_intl_analysis.txt")
            with open(source_file, "w", encoding="utf-8") as f:
                f.write(f"ì†ŒìŠ¤ #{index+1} êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ ë¶„ì„\n")
                f.write("="*50 + "\n\n")
                f.write(analysis)
            
            print(f"âœ… ì†ŒìŠ¤ #{index+1} êµ­ì œê´€ê³„/ì§€ì •í•™ ë¶„ì„ ì™„ë£Œ")
            
            return {
                "index": index+1,
                "analysis": analysis,
                "success": True
            }
            
        except Exception as e:
            print(f"âš ï¸ ì†ŒìŠ¤ #{index+1} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ê°„ë‹¨í•œ ìš”ì•½ ì‹œë„
            return {
                "index": index+1,
                "analysis": f"[ë¶„ì„ ì‹¤íŒ¨: {str(e)}]\n\nì†ŒìŠ¤ ë‚´ìš© ì¼ë¶€:\n{text[:500]}...",
                "success": False
            }
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
    with concurrent.futures.ThreadPoolExecutor(max_workers=worker_count) as executor:
        # ì¼ê´„ ì œì¶œ ëŒ€ì‹  í•˜ë‚˜ì”© ì œì¶œí•˜ê³  ì™„ë£Œë  ë•Œë§ˆë‹¤ ë‹¤ìŒ ì‘ì—… ì œì¶œ
        # ì´ë ‡ê²Œ í•˜ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  ë¶€í•˜ë¥¼ ë¶„ì‚°ì‹œí‚¬ ìˆ˜ ìˆìŒ
        future_to_item = {}
        remaining_items = list(valid_texts)
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ ì œì¶œ (ì›Œì»¤ ìˆ˜ë§Œí¼)
        initial_batch = remaining_items[:worker_count]
        remaining_items = remaining_items[worker_count:]
        
        for item in initial_batch:
            future = executor.submit(analyze_source, item)
            future_to_item[future] = item[0]
        
        # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬ ë° ìƒˆ ì‘ì—… ì œì¶œ
        while future_to_item:
            # ì™„ë£Œëœ ì‘ì—… í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
            done, _ = concurrent.futures.wait(
                future_to_item, 
                return_when=concurrent.futures.FIRST_COMPLETED
            )
            
            for future in done:
                try:
                    result = future.result()
                    source_summaries.append(result)
                    
                    # ì™„ë£Œëœ í•­ëª© ì¶œë ¥
                    index = future_to_item[future]
                    if result.get("success", False):
                        print(f"âœ… ì†ŒìŠ¤ #{index+1} ë¶„ì„ ì™„ë£Œ")
                    else:
                        print(f"âš ï¸ ì†ŒìŠ¤ #{index+1} ë¶„ì„ ê²°ê³¼ ë¶ˆì¶©ë¶„")
                    
                    # ìƒˆ ì‘ì—… ì œì¶œ (ë‚¨ì€ í•­ëª©ì´ ìˆëŠ” ê²½ìš°)
                    if remaining_items:
                        new_item = remaining_items.pop(0)
                        new_future = executor.submit(analyze_source, new_item)
                        future_to_item[new_future] = new_item[0]
                    
                except Exception as e:
                    index = future_to_item[future]
                    print(f"âš ï¸ ì†ŒìŠ¤ #{index+1} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                    source_summaries.append({
                        "index": index+1,
                        "analysis": f"[ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}]",
                        "success": False
                    })
                
                # ì²˜ë¦¬ëœ future ì‚­ì œ
                del future_to_item[future]
    
    # ì¸ë±ìŠ¤ ìˆœìœ¼ë¡œ ì •ë ¬
    source_summaries.sort(key=lambda x: x["index"])
    
    # ì„±ê³µí•œ ë¶„ì„ ê°œìˆ˜ í™•ì¸
    success_count = sum(1 for s in source_summaries if s.get("success", False))
    print(f"ğŸ“Š {len(source_summaries)}ê°œ ì†ŒìŠ¤ ì¤‘ {success_count}ê°œ ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ ì™„ë£Œ")
    
    return source_summaries

def create_integrated_analysis(source_summaries: List[Dict[str, Any]], topic: str, structure: str, output_dir: str) -> str:
    """
    ê°œë³„ ì†ŒìŠ¤ ë¶„ì„ì„ í†µí•©í•˜ì—¬ ì¢…í•©ì ì¸ ë¶„ì„ ìƒì„±
    
    Args:
        source_summaries: ê° ì†ŒìŠ¤ë³„ ë¶„ì„ ê²°ê³¼
        topic: ì½˜í…ì¸  ì£¼ì œ
        structure: ë…¼ë¦¬ êµ¬ì¡°
        output_dir: ê²°ê³¼ë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        í†µí•© ë¶„ì„ í…ìŠ¤íŠ¸
    """
    # ëª¨ë“  ë¶„ì„ ê²°ê³¼ ì—°ê²°
    all_analyses = "\n\n".join([
        f"--- ì†ŒìŠ¤ #{s['index']} êµ­ì œê´€ê³„/ì§€ì •í•™ ë¶„ì„ ---\n{s['analysis']}" 
        for s in source_summaries
    ])
    
    # ì „ì²´ ë¶„ì„ ê²°ê³¼ ì €ì¥
    with open(os.path.join(output_dir, "all_intl_analyses.txt"), "w", encoding="utf-8") as f:
        f.write(all_analyses)
    
    integration_prompt = f"""
ë‹¹ì‹ ì€ êµ­ì œê´€ê³„, ì§€ì •í•™, ì„¸ê³„ì‚¬ ë¶„ì•¼ì˜ ìµœê³  ì „ë¬¸ê°€ë¡œ, ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ì¢…í•©í•´ êµ­ì œì •ì¹˜ì™€ ì§€ì •í•™ì— ê´€í•œ ì „ë¬¸ì ì¸ í†µí•© ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ì œ: {topic}
êµ¬ì¡°: {structure}

ë‹¤ìŒì€ {len(source_summaries)}ê°œ ì†ŒìŠ¤ì— ëŒ€í•œ ê°œë³„ êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ ë¶„ì„ì…ë‹ˆë‹¤:

{all_analyses}

ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ì œì— ê´€í•œ ì¢…í•©ì ì¸ êµ­ì œê´€ê³„/ì§€ì •í•™ ì „ë¬¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”. ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

1. ì‚¬ì•ˆì˜ ëª…í™•í•œ êµ­ì œì •ì¹˜ì  ë§¥ë½ê³¼ ë°°ê²½
2. ê´€ë ¨ëœ ì£¼ìš” êµ­ê°€ë“¤ê³¼ í–‰ìœ„ìë“¤ì˜ ì…ì¥ê³¼ ì´í•´ê´€ê³„
3. ì§€ì •í•™ì  ì¤‘ìš”ì„±ê³¼ ì „ëµì  í•¨ì˜
4. ê´€ë ¨ ì—­ì‚¬ì  ì„ ë¡€ì™€ ë¹„êµ ë¶„ì„
5. ì£¼ìš” êµ­ì œê´€ê³„ ì´ë¡ (í˜„ì‹¤ì£¼ì˜, ììœ ì£¼ì˜, êµ¬ì„±ì£¼ì˜ ë“±)ì˜ ê´€ì ì—ì„œ í•´ì„
6. ì§€ì—­ ë° ê¸€ë¡œë²Œ ì•ˆë³´ êµ¬ì¡°ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
7. ë‹¨ê¸° ë° ì¤‘ì¥ê¸° ì‹œë‚˜ë¦¬ì˜¤ì™€ ì „ë§
8. ì •ì±…ì  ì‹œì‚¬ì ê³¼ í•¨ì˜
9. êµ­ì œë²• ë° êµ­ì œê·œë²”ì  ê´€ì ì—ì„œì˜ ê³ ë ¤ì‚¬í•­
10. ì´ìŠˆì˜ ì—­ì‚¬ì , ë¬¸í™”ì , ê²½ì œì  ì°¨ì›ì˜ ë³µí•©ì  ë¶„ì„

íŠ¹íˆ ë‹¤ìŒì— ì£¼ì˜í•˜ì„¸ìš”:
- ê°ê´€ì ì´ê³  ê· í˜• ìˆëŠ” ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ì—­ì‚¬ì  ì„ ë¡€ë¥¼ í¬í•¨í•˜ì„¸ìš”
- ì¤‘ìš”í•œ ë‚ ì§œ, ì‚¬ê±´, í•©ì˜, ì¡°ì•½ ë“±ì˜ ì •í™•í•œ ì •ë³´ë¥¼ ì œì‹œí•˜ì„¸ìš”
- ëª¨ìˆœë˜ëŠ” ì •ë³´ê°€ ìˆì„ ê²½ìš° ì¶œì²˜ì˜ ì‹ ë¢°ì„±ì„ í‰ê°€í•˜ì—¬ ê°€ì¥ ì •í™•í•œ ì •ë³´ë¥¼ ì œì‹œí•˜ì„¸ìš”
- ì§€ì •í•™ì  ë¶„ì„ê³¼ í•¨ê»˜ ì§€ì—­ì˜ ì‚¬íšŒë¬¸í™”ì , ê²½ì œì , ì—­ì‚¬ì  ë§¥ë½ë„ ê³ ë ¤í•˜ì„¸ìš”
- ì •ì¹˜ì  ì¤‘ë¦½ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ì „ë¬¸ê°€ì  í†µì°°ë ¥ì„ ë³´ì—¬ì£¼ì„¸ìš”
"""
    
    try:
        def make_api_call():
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": integration_prompt}],
                temperature=0.4,
            )
            return res.choices[0].message.content.strip()
        
        # ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ API í˜¸ì¶œ
        integrated_analysis = api_call_with_retry(make_api_call)
        
        # í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥
        with open(os.path.join(output_dir, "integrated_intl_analysis.txt"), "w", encoding="utf-8") as f:
            f.write(integrated_analysis)
            
        print("âœ… êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ í†µí•© ë¶„ì„ ì™„ë£Œ")
        return integrated_analysis
        
    except Exception as e:
        print(f"âš ï¸ í†µí•© ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return ""
def create_fallback_integrated_analysis(source_summaries: List[Dict[str, Any]]) -> str:
    """
    í†µí•© ë¶„ì„ ìƒì„± ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ìš”ì•½ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        source_summaries: ê° ì†ŒìŠ¤ë³„ ë¶„ì„ ê²°ê³¼
        
    Returns:
        ëŒ€ì²´ í†µí•© ë¶„ì„ í…ìŠ¤íŠ¸
    """
    print("âš ï¸ ëŒ€ì²´ í†µí•© ë¶„ì„ ìƒì„± ì¤‘...")
    
    # ê° ì†ŒìŠ¤ì˜ ì²« 5ì¤„ ì¶”ì¶œí•˜ì—¬ ê²°í•©
    fallback_analysis = "## ì†ŒìŠ¤ë³„ í•µì‹¬ ë¶„ì„ ìš”ì•½\n\n"
    
    for s in source_summaries:
        lines = s['analysis'].split('\n')
        summary_lines = lines[:min(5, len(lines))]
        
        fallback_analysis += f"### ì†ŒìŠ¤ #{s['index']} ì£¼ìš” ë‚´ìš©\n"
        fallback_analysis += '\n'.join(summary_lines)
        fallback_analysis += "\n\n"
    
    fallback_analysis += "## ì¢…í•© ê´€ì \n"
    fallback_analysis += "ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ë¶„ì„ì„ ì¢…í•©í•œ ê²°ê³¼, ë‹¤ìŒê³¼ ê°™ì€ ê³µí†µëœ êµ°ì‚¬/êµ­ì œì •ì¹˜ì  ê´€ì ì´ ë„ì¶œë©ë‹ˆë‹¤. "
    fallback_analysis += "ê° ì†ŒìŠ¤ì˜ ì£¼ìš” ê´€ì ì„ ê³ ë ¤í•˜ì—¬ ì´ ì£¼ì œì— ëŒ€í•œ ê· í˜• ì¡íŒ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    return fallback_analysis

def create_longform_script(integrated_analysis: str, topic: str, structure: str, additional_instructions: str, output_dir: str) -> str:
    """
    í†µí•© ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ 9-11ë¶„ ê¸¸ì´ì˜ ë¡±í¼ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    
    Args:
        integrated_analysis: í†µí•© ë¶„ì„ í…ìŠ¤íŠ¸
        topic: ì½˜í…ì¸  ì£¼ì œ
        structure: ë…¼ë¦¬ êµ¬ì¡°
        additional_instructions: ì¶”ê°€ ì§€ì‹œì‚¬í•­
        output_dir: ê²°ê³¼ë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ìµœì¢… ë¡±í¼ ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸
    """
    script_prompt = f"""
ë‹¹ì‹ ì€ êµ­ì œê´€ê³„, ì§€ì •í•™, ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³µì¡í•œ êµ­ì œì •ì¹˜ì™€ ì§€ì •í•™ì  ì£¼ì œë¥¼ ì „ë¬¸ì ì´ë©´ì„œë„ í¥ë¯¸ë¡­ê²Œ ì „ë‹¬í•˜ëŠ” ì½˜í…ì¸ ë¥¼ ì œì‘í•©ë‹ˆë‹¤.

ì£¼ì œ: {topic}
êµ¬ì¡°: {structure}

í†µí•© êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ë¶„ì„:
{integrated_analysis}

ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ "{structure}" êµ¬ì¡°ë¥¼ ë”°ë¥´ëŠ” ì „ë¬¸ì ì¸ ì½˜í…ì¸  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” 9-11ë¶„ ë¶„ëŸ‰ì˜ ì˜ìƒ(ì•½ 2700-3300ì)ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìŒ ì‚¬í•­ì— íŠ¹ë³„íˆ ìœ ì˜í•˜ì„¸ìš”:

1. êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ë¡œì„œì˜ ê¶Œìœ„ì™€ ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ë˜, í¥ë¯¸ë¡­ê³  ë§¤ë ¥ì ì¸ ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œ ë‚´ìš©ì„ ì „ë‹¬í•˜ì„¸ìš”
2. ì‹œì²­ìì˜ ê´€ì‹¬ì„ ì‚¬ë¡œì¡ëŠ” ê°•ë ¥í•œ ì˜¤í”„ë‹ìœ¼ë¡œ ì‹œì‘í•˜ê³ , í•µì‹¬ ì§ˆë¬¸ì´ë‚˜ ì£¼ìš” ëª…ì œë¡œ í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ì„¸ìš”
3. ë³µì¡í•œ êµ­ì œì •ì¹˜ì  ê°œë…ê³¼ ì§€ì •í•™ ì´ë¡ ì„ ëª…í™•í•œ ë¹„ìœ ì™€ ì‹œê°ì  ì˜ˆì‹œë¡œ ì„¤ëª…í•˜ì„¸ìš”
4. ì ì ˆí•œ ì§€ì ì—ì„œ ì£¼ìš” êµ­ì œê´€ê³„ í•™ì, ì—­ì‚¬ì  ì¸ë¬¼, ì •ì¹˜ ì§€ë„ì, ì—°êµ¬ê¸°ê´€ ë“±ì„ ì¸ìš©í•˜ì—¬ ì‹ ë¢°ì„±ì„ ê°•í™”í•˜ì„¸ìš”
5. ì˜ìƒ ìš”ì†ŒëŠ” [ì˜ìƒ: ì„¤ëª…] í˜•ì‹ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ì— í†µí•©í•˜ì„¸ìš”
6. ì—­ì‚¬ì  ì‚¬ë¡€ì™€ í˜„ëŒ€ êµ­ì œê´€ê³„ì˜ ì—°ê²°ì ì„ ê°•ì¡°í•˜ë©° ë§¥ë½ì„ ì œê³µí•˜ì„¸ìš”
7. ê· í˜• ì¡íŒ ê´€ì ì„ ì œì‹œí•˜ë˜, êµ­ì œê´€ê³„/ì§€ì •í•™ ì „ë¬¸ê°€ë¡œì„œì˜ í†µì°°ë ¥ì„ ê°•ì¡°í•˜ì„¸ìš”
8. ë¶„ì„ì ì´ë©´ì„œë„ ë§¤ë ¥ì ì¸ ìŠ¤í† ë¦¬í…”ë§ ìš”ì†Œë¥¼ í¬í•¨í•˜ì—¬ ì‹œì²­ìê°€ ëê¹Œì§€ ì‹œì²­í•˜ê²Œ í•˜ì„¸ìš”
9. ë…¼ë¦¬ì ì¸ íë¦„ì„ ìœ ì§€í•˜ê³ , ê° í¬ì¸íŠ¸ ê°„ì˜ ì—°ê²°ì„ ëª…í™•íˆ í•˜ì„¸ìš”
10. ìŠ¤í¬ë¦½íŠ¸ ê²°ë¡ ì—ì„œëŠ” í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ì‹œì²­ìì—ê²Œ ìƒê°í•´ë³¼ ë§Œí•œ ì§ˆë¬¸ì´ë‚˜ ì „ë§ì„ ì œì‹œí•˜ì„¸ìš”
11. "ì¢‹ì•„ìš”", "êµ¬ë…", "ì•Œë¦¼ ì„¤ì •" ë“± ì±„ë„ í”„ë¡œëª¨ì…˜ ì–¸ê¸‰ì€ ì™„ì „íˆ ë°°ì œí•˜ì„¸ìš”
12. ì„œë‘ì™€ ê²°ë¡ ì—ì„œ ì±„ë„ ì†Œê°œë‚˜ í™˜ì˜ ì¸ì‚¬ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš” - ì¦‰ì‹œ ì£¼ì œë¡œ ë“¤ì–´ê°€ì„¸ìš”

ì¤‘ìš”: ì„¹ì…˜ ì œëª©(ì˜ˆ: "Introduction", "Development" ë“±)ê³¼ [ì˜ìƒ: ...] íƒœê·¸ëŠ” TTS ìŒì„±ìœ¼ë¡œ ì½íˆì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìš”ì†ŒëŠ” í¸ì§‘ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.

ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ìŠ¤íƒ€ì¼ ìš”ì†Œë¥¼ í¬í•¨í•˜ì„¸ìš”:
- ê¶Œìœ„ ìˆê³  ì „ë¬¸ì ì´ì§€ë§Œ ì¹œê·¼í•˜ê³  ë§¤ë ¥ì ì¸ í†¤
- êµ­ì œê´€ê³„/ì§€ì •í•™ ì „ë¬¸ìš©ì–´ ì‚¬ìš© ì‹œ ê°„ê²°í•œ ì„¤ëª… ë³‘í–‰
- ê°ê´€ì ì´ê³  ë¶„ì„ì ì¸ ì ‘ê·¼ ë°©ì‹
- ì ì ˆí•œ ì§€ì ì—ì„œ ì „ë¬¸ê°€ì  í†µì°° ì¶”ê°€
- ê° ì„¹ì…˜ì´ ëë‚  ë•Œë§ˆë‹¤ ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ëŠ” íë¦„
- ì‹œê°ê°ì  í‘œí˜„ì´ í’ë¶€í•œ ì„¤ëª…
- ë…¼ë¦¬ì ì¸ íë¦„ê³¼ í•´ë‹¹ ë‹¨ë½ì— ë‚´ìš©ì— ë§ëŠ” ì‚¬ë¡€ì™€ ìˆ˜ì¹˜ ìë£Œ í™œìš©
- ì¤‘ìš”í•œ í¬ì¸íŠ¸ëŠ” ëª…í™•í•˜ê³  ê¸°ì–µí•˜ê¸° ì‰¬ìš´ ë¬¸êµ¬ë¡œ ê°•ì¡°
- ê²°ë¡  ë¶€ë¶„ì—ì„œëŠ” ì£¼ì œì™€ ê´€ë ¨ëœ ê¹Šì´ ìˆëŠ” ì§ˆë¬¸ì´ë‚˜ ì „ë§ìœ¼ë¡œ ë§ˆë¬´ë¦¬

{additional_instructions}

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ í•œêµ­ì–´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”. í•œêµ­ ì‹œì²­ìë“¤ì—ê²Œ ì¹œìˆ™í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ ëŠë‚Œì„ ì¤„ ìˆ˜ ìˆë„ë¡ ì‘ì„±í•´ì£¼ì„¸ìš”. ìµœì¢… ìŠ¤í¬ë¦½íŠ¸ëŠ” ì•½ 2700-3300ì ì •ë„ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
"""
    
    try:
        # API í˜¸ì¶œ í•¨ìˆ˜
        def make_api_call():
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": script_prompt}],
                temperature=0.7,
                max_tokens=4000,
            )
            return res.choices[0].message.content.strip()
        
        final_script = api_call_with_retry(make_api_call)
        
        # ìŠ¤í¬ë¦½íŠ¸ í¬ë§·íŒ… ê°œì„ 
        final_script = format_script(final_script)
        
        # ê²°ê³¼ë¬¼ ì €ì¥
        script_file = os.path.join(output_dir, "final_longform_script.txt")
        with open(script_file, "w", encoding="utf-8") as f:
            f.write(final_script)
            
        return final_script
        
    except Exception as e:
        print(f"âŒ ë¡±í¼ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return ""

def create_shortform_script(integrated_analysis: str, topic: str, shortform_number: int, output_dir: str) -> str:
    """
    í†µí•© ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ìˆí¼ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    
    Args:
        integrated_analysis: í†µí•© ë¶„ì„ í…ìŠ¤íŠ¸
        topic: ì½˜í…ì¸  ì£¼ì œ
        shortform_number: ìˆí¼ ë²ˆí˜¸(1, 2, 3)
        output_dir: ê²°ê³¼ë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ìˆí¼ ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸
    """
    # ìˆí¼ë³„ ì°¨ë³„í™” í¬ì¸íŠ¸ ì„¤ì •
    if shortform_number == 1:
        shortform_focus = "ì§€ì •í•™ì ìœ¼ë¡œ ê°€ì¥ ì¶©ê²©ì ì´ê±°ë‚˜ í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤ì— ì§‘ì¤‘í•˜ì„¸ìš”. ì‹œì²­ìë“¤ì´ 'ì™€, ì´ëŸ° ì‚¬ì‹¤ì´!' í•˜ê³  ë°˜ì‘í•  ë§Œí•œ ì½˜í…ì¸ ë¥¼ ì œì‘í•˜ì„¸ìš”."
        shortform_title = "í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤"
    elif shortform_number == 2:
        shortform_focus = "ì—­ì‚¬ì  ë§¥ë½ê³¼ í˜„ëŒ€ êµ­ì œê´€ê³„ì˜ ì—°ê²°ì ì„ ê°•ì¡°í•˜ì„¸ìš”. ê³¼ê±° ì‚¬ë¡€ê°€ í˜„ì¬ì— ì–´ë–¤ í•¨ì˜ë¥¼ ê°–ëŠ”ì§€ ì§‘ì¤‘ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”."
        shortform_title = "ì—­ì‚¬ì  ë§¥ë½"
    else:
        shortform_focus = "ì´ ì´ìŠˆì˜ ë¯¸ë˜ ì „ë§ê³¼ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ì§‘ì¤‘í•˜ì„¸ìš”. ì£¼ìš” í–‰ìœ„ìë“¤ì˜ ë‹¤ìŒ í–‰ë³´ì™€ ì¥ê¸°ì  ì˜í–¥ì„ ë¶„ì„í•˜ì„¸ìš”."
        shortform_title = "ë¯¸ë˜ ì „ë§"
    
    script_prompt = f"""
ë‹¹ì‹ ì€ êµ­ì œê´€ê³„, ì§€ì •í•™, ì„¸ê³„ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì†Œì…œ ë¯¸ë””ì–´ ìˆí¼ ì½˜í…ì¸ ìš© ì§§ê³  ê°•ë ¥í•œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ì£¼ì œ: {topic}
ìˆí¼ ìœ í˜•: #{shortform_number} - {shortform_title}

í†µí•© êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ ë¶„ì„:
{integrated_analysis}

ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ 50-80ì´ˆ ê¸¸ì´ì˜ ìˆí¼ ë¹„ë””ì˜¤ë¥¼ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”(ì•½ 250-400ì).
{shortform_focus}

êµ­ì œê´€ê³„/ì§€ì •í•™/ì„¸ê³„ì‚¬ì˜ í•µì‹¬ì— ì¤‘ì ì„ ë‘ê³  ë‹¤ìŒ ìš”ì†Œë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”:
1. ì‹œì²­ìì˜ ê´€ì‹¬ì„ ì¦‰ì‹œ ì‚¬ë¡œì¡ëŠ” ë„ì…ë¶€
2. ì£¼ì œì— ëŒ€í•œ í•µì‹¬ í†µì°° 1-2ê°œ
3. êµ­ì œê´€ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼ ì¤‘ìš”ì„± ì„¤ëª…
4. ë†€ë¼ìš´ ì‚¬ì‹¤ì´ë‚˜ í¥ë¯¸ë¡œìš´ ê´€ì 

ìˆí¼ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì§€ì¹¨:
1. ì¦‰ì‹œ ê´€ì‹¬ì„ ë„ëŠ” ê°•ë ¥í•œ ë¬¸ì¥ì´ë‚˜ ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
2. í•µì‹¬ ë©”ì‹œì§€ í•˜ë‚˜ì— ì§‘ì¤‘í•˜ì„¸ìš”
3. ë¶ˆí•„ìš”í•œ ì„¸ë¶€ì‚¬í•­ì€ ì œê±°í•˜ê³  í•µì‹¬ ë‚´ìš©ë§Œ ë‹´ë°±í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”
4. ì—­ë™ì ì´ê³  ì‹œê°ì ì¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
5. ì˜ìƒ ìš”ì†ŒëŠ” **[ì˜ìƒ: ì„¤ëª…]** í˜•ì‹ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ì— í†µí•©í•˜ì„¸ìš”
6. ì‹œì²­ìì˜ ê¶ê¸ˆì¦ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ ìƒê°ê±°ë¦¬ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”
7. ì ˆëŒ€ë¡œ ì±„ë„ í™ë³´ë‚˜ êµ¬ë… ìš”ì²­ ë“±ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”

ì¤‘ìš”: ìŠ¤í¬ë¦½íŠ¸ ë‚´ ëª¨ë“  í˜•ì‹ì€ ì¼ê´€ë˜ê²Œ ìœ ì§€í•˜ì„¸ìš”. ì„¹ì…˜ êµ¬ë¶„ì´ í•„ìš”í•˜ë©´ í•­ìƒ **[ì˜ìƒ: ì„¤ëª…]** í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, ì†Œì…œ ë¯¸ë””ì–´ ì‚¬ìš©ìë“¤ì˜ ì£¼ì˜ë¥¼ ëŒ ìˆ˜ ìˆë„ë¡ í¥ë¯¸ë¡­ê³  ë§¤ë ¥ì ì¸ ë‚´ìš©ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”. ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ëŠ” 250-400ì ì‚¬ì´ë¡œ ìœ ì§€í•´ì£¼ì„¸ìš”.
"""
    
    try:
        # API í˜¸ì¶œ í•¨ìˆ˜
        def make_api_call():
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": script_prompt}],
                temperature=0.8,
                max_tokens=1000,
            )
            return res.choices[0].message.content.strip()
        
        shortform_script = api_call_with_retry(make_api_call)
        
        # ìŠ¤í¬ë¦½íŠ¸ í¬ë§·íŒ… ê°œì„ 
        shortform_script = format_script(shortform_script)
        
        # ê²°ê³¼ë¬¼ ì €ì¥
        script_file = os.path.join(output_dir, f"final_shortform{shortform_number}_script.txt")
        with open(script_file, "w", encoding="utf-8") as f:
            f.write(shortform_script)
            
        return shortform_script
        
    except Exception as e:
        print(f"âŒ ìˆí¼ ìŠ¤í¬ë¦½íŠ¸ #{shortform_number} ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return ""


# ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ - create_longform_scriptë¡œ ëŒ€ì²´ë¨
# def create_final_script(integrated_analysis: str, topic: str, structure: str, additional_instructions: str, output_dir: str) -> str:
#     """
#     í†µí•© ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    
#     Args:
#         integrated_analysis: í†µí•© ë¶„ì„ í…ìŠ¤íŠ¸
#         topic: ì½˜í…ì¸  ì£¼ì œ
#         structure: ë…¼ë¦¬ êµ¬ì¡°
#         additional_instructions: ì¶”ê°€ ì§€ì‹œì‚¬í•­
#         output_dir: ê²°ê³¼ë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
#     Returns:
#         ìµœì¢… ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸
#     """
#     script_prompt = f"""
# ë‹¹ì‹ ì€ êµ°ì‚¬ ë° êµ­ì œì •ì¹˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³µì¡í•œ êµ°ì‚¬ ë° ì§€ì •í•™ì  ì£¼ì œë¥¼ ì „ë¬¸ì ì´ê³  ë‹´ë°±í•˜ê²Œ ì „ë‹¬í•˜ëŠ” ì½˜í…ì¸ ë¥¼ ì œì‘í•©ë‹ˆë‹¤.

# ì£¼ì œ: {topic}
# êµ¬ì¡°: {structure}

# í†µí•© êµ°ì‚¬/êµ­ì œì •ì¹˜ ë¶„ì„:
# {integrated_analysis}

# ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ "{structure}" êµ¬ì¡°ë¥¼ ë”°ë¥´ëŠ” ì „ë¬¸ì ì¸ ì½˜í…ì¸  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
# ë‹¤ìŒ ì‚¬í•­ì— íŠ¹ë³„íˆ ìœ ì˜í•˜ì„¸ìš”:

# 1. êµ­ì œì •ì¹˜/êµ°ì‚¬ ì „ë¬¸ê°€ë¡œì„œì˜ ê¶Œìœ„ì™€ ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ê³ , ë‹´ë°±í•˜ê³  ì •ë³´ ì¤‘ì‹¬ì ì¸ ë‚´ìš© ì „ë‹¬ì— ì§‘ì¤‘í•˜ì„¸ìš”
# 2. ì‹œì²­ìì˜ ê´€ì‹¬ì„ ì‚¬ë¡œì¡ëŠ” ê°•ë ¥í•œ ì˜¤í”„ë‹ìœ¼ë¡œ ì‹œì‘í•˜ê³ , í•µì‹¬ ì§ˆë¬¸ì´ë‚˜ ì£¼ìš” ëª…ì œë¡œ í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ì„¸ìš”
# 3. ë³µì¡í•œ êµ°ì‚¬ì /ì§€ì •í•™ì  ê°œë…ì„ ëª…í™•í•œ ë¹„ìœ ì™€ ì‹œê°ì  ì˜ˆì‹œë¡œ ì„¤ëª…í•˜ì„¸ìš”
# 4. ì ì ˆí•œ ì§€ì ì—ì„œ ì£¼ìš” êµ°ì‚¬ ì´ë¡ ê°€, ì•ˆë³´ ì „ë¬¸ê°€, êµ­ì œê´€ê³„ í•™ì, ì—°êµ¬ê¸°ê´€, ì–¸ë¡  ë“±ì„ ì¸ìš©í•˜ì—¬ ì‹ ë¢°ì„±ì„ ê°•í™”í•˜ì„¸ìš”
# 5. ì˜ìƒ ìš”ì†ŒëŠ” [ì˜ìƒ: ì„¤ëª…] í˜•ì‹ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ì— í†µí•©í•˜ì„¸ìš”
# 6. ì¤‘ìš”í•œ êµ°ì‚¬ì /ì§€ì •í•™ì  ì‚¬ë¡€ë‚˜ ì—­ì‚¬ì  ì‚¬ê±´ì„ í™œìš©í•˜ì—¬ ì‹œì²­ìì˜ ì´í•´ë¥¼ ë•ê³  ê´€ì‹¬ì„ ìœ ì§€í•˜ì„¸ìš”
# 7. ê· í˜• ì¡íŒ ê´€ì ì„ ì œì‹œí•˜ë˜, êµ­ì œì •ì¹˜/êµ°ì‚¬ ì „ë¬¸ê°€ë¡œì„œì˜ í†µì°°ë ¥ì„ ê°•ì¡°í•˜ì„¸ìš”
# 8. ë¶„ì„ì ì´ë©´ì„œë„ ë§¤ë ¥ì ì¸ ìŠ¤í† ë¦¬í…”ë§ ìš”ì†Œë¥¼ í¬í•¨í•˜ì—¬ ì‹œì²­ìê°€ ëê¹Œì§€ ì‹œì²­í•˜ê²Œ í•˜ì„¸ìš”
# 9. ë…¼ë¦¬ì ì¸ íë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ì§€í•˜ê³ , ê° í¬ì¸íŠ¸ ê°„ì˜ ì—°ê²°ì„ ëª…í™•íˆ í•˜ì„¸ìš”
# 10. ìŠ¤í¬ë¦½íŠ¸ ê²°ë¡ ì—ì„œëŠ” í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ì‹œì²­ìì—ê²Œ ìƒê°í•´ë³¼ ë§Œí•œ ì§ˆë¬¸ì´ë‚˜ ì „ë§ì„ ì œì‹œí•˜ì„¸ìš”
# 11. "ì¢‹ì•„ìš”", "êµ¬ë…", "ì•Œë¦¼ ì„¤ì •" ë“± ì±„ë„ í”„ë¡œëª¨ì…˜ ì–¸ê¸‰ì€ ì™„ì „íˆ ë°°ì œí•˜ì„¸ìš”
# 12. ì„œë‘ì™€ ê²°ë¡ ì—ì„œ ì±„ë„ ì†Œê°œë‚˜ í™˜ì˜ ì¸ì‚¬ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš” - ì¦‰ì‹œ ì£¼ì œë¡œ ë“¤ì–´ê°€ì„¸ìš”

# ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ìŠ¤íƒ€ì¼ ìš”ì†Œë¥¼ í¬í•¨í•˜ì„¸ìš”:
# - ê¶Œìœ„ ìˆê³  ì „ë¬¸ì ì¸ í†¤
# - êµ°ì‚¬/êµ­ì œì •ì¹˜ ì „ë¬¸ìš©ì–´ ì‚¬ìš© ì‹œ ê°„ê²°í•œ ì„¤ëª… ë³‘í–‰
# - ê°ê´€ì ì´ê³  ë¶„ì„ì ì¸ ì ‘ê·¼ ë°©ì‹
# - ì ì ˆí•œ ì§€ì ì—ì„œ ì „ë¬¸ê°€ì  í†µì°° ì¶”ê°€
# - ê° ì„¹ì…˜ì´ ëë‚  ë•Œë§ˆë‹¤ ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ëŠ” íë¦„
# - ë…¼ë¦¬ì ì¸ íë¦„ê³¼ í•´ë‹¹ ë‹¨ë½ì— ë‚´ìš©ì— ë§ëŠ” ìˆ˜ì¹˜ ìë£Œê°€ ìˆë‹¤ë©´ í™œìš©
# - ì¤‘ìš”í•œ í¬ì¸íŠ¸ëŠ” ëª…í™•í•˜ê³  ê¸°ì–µí•˜ê¸° ì‰¬ìš´ ë¬¸êµ¬ë¡œ ê°•ì¡°
# - ê²°ë¡  ë¶€ë¶„ì—ì„œëŠ” ì£¼ì œì™€ ê´€ë ¨ëœ ê¹Šì´ ìˆëŠ” ì§ˆë¬¸ì´ë‚˜ ì „ë§ìœ¼ë¡œ ë§ˆë¬´ë¦¬

# {additional_instructions}

# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì˜ì–´ê¶Œ ìœ íŠœë¸Œ ì‹œì²­ìë¥¼ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤. ì™„ë²½í•œ ì›ì–´ë¯¼ ìˆ˜ì¤€ì˜ ì˜ì–´ë¡œ ì‘ì„±í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ ì½˜í…ì¸ ë¥¼ ì œê³µí•˜ì„¸ìš”.
# """
    
#     try:
#         # API í˜¸ì¶œ í•¨ìˆ˜
#         def make_api_call():
#             res = client.chat.completions.create(
#                 model="gpt-4o",
#                 messages=[{"role": "user", "content": script_prompt}],
#                 temperature=0.7,
#                 max_tokens=4000,
#             )
#             return res.choices[0].message.content.strip()
        
#         final_script = api_call_with_retry(make_api_call)
        
#         # ìŠ¤í¬ë¦½íŠ¸ í¬ë§·íŒ… ê°œì„ 
#         final_script = format_script(final_script)
        
#         # ê²°ê³¼ë¬¼ ì €ì¥
#         script_file = os.path.join(output_dir, "final_military_script.txt")
#         with open(script_file, "w", encoding="utf-8") as f:
#             f.write(final_script)
            
#         return final_script
        
#     except Exception as e:
#         print(f"âŒ ìµœì¢… ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
#         return ""


def format_script(script: str) -> str:
    """ìŠ¤í¬ë¦½íŠ¸ í˜•ì‹ì„ ê°œì„ """
    # ì˜ìƒ ì§€ì‹œì‚¬í•­ í¬ë§· í†µì¼
    script = re.sub(r'\[ì˜ìƒ[ \t]*:[ \t]*(.*?)\]', r'[ì˜ìƒ: \1]', script)
    script = re.sub(r'\[Video[ \t]*:[ \t]*(.*?)\]', r'[ì˜ìƒ: \1]', script)
    
    # ë¶ˆí•„ìš”í•œ ì—¬ë°± ì œê±°
    script = re.sub(r'\n{3,}', '\n\n', script)
    
    # êµ¬ê°„ í‘œì‹œê°€ ìˆëŠ” ê²½ìš° ê°•ì¡°
    sections = ["ì„œë¡ ", "ë³¸ë¡ ", "ê²°ë¡ ", "ë„ì…", "ì „ê°œ", "ë§ˆë¬´ë¦¬", "Introduction", "Main Body", "Conclusion"]
    for section in sections:
        script = re.sub(f'(^|\n)({section})(:|\.|\n)', f'\\1\n## {section} ##\\3', script, flags=re.IGNORECASE)
    
    return script

@lru_cache(maxsize=32)
def extract_military_references(analysis: str) -> List[Dict[str, str]]:
    """í†µí•© ë¶„ì„ì—ì„œ êµ°ì‚¬/êµ­ì œì •ì¹˜ ê´€ë ¨ ì „ë¬¸ê°€, ì—°êµ¬ê¸°ê´€, ì´ë¡  ë“±ì˜ ì°¸ì¡° ì¶”ì¶œ"""
    references = []
    
    # ì „ë¬¸ê°€ ì´ë¦„ íŒ¨í„´
    expert_pattern = r'([A-Z][a-z]+(?:\s[A-Z][a-z]+)+)(?:\s*(?:\(|\,|\ëŠ”|\ì€))'
    expert_matches = re.finditer(expert_pattern, analysis)
    for match in expert_matches:
        name = match.group(1).strip()
        # ì¼ë°˜ì ì¸ ì´ë¦„ì´ ì•„ë‹Œ ê²½ìš°ë§Œ (ìµœì†Œ 2ë‹¨ì–´ ì´ìƒ)
        if ' ' in name and len(name) > 5:
            references.append({
                "type": "expert",
                "name": name,
                "context": analysis[max(0, match.start() - 30):match.end() + 50]
            })
    
    # ì—°êµ¬ê¸°ê´€ íŒ¨í„´
    institution_pattern = r'((?:[A-Z][a-z]*\s*)+(?:Institute|Center|Council|College|University|ì—°êµ¬ì†Œ|ì—°êµ¬ì›|ì„¼í„°|ê¸°ê´€))'
    institution_matches = re.finditer(institution_pattern, analysis)
    for match in institution_matches:
        institution = match.group(1).strip()
        if len(institution) > 8:  # ì–´ëŠ ì •ë„ ê¸¸ì´ê°€ ìˆëŠ” ê¸°ê´€ëª…ë§Œ
            references.append({
                "type": "institution",
                "name": institution,
                "context": analysis[max(0, match.start() - 30):match.end() + 50]
            })
    
    # ì´ë¡ /ë…íŠ¸ë¦° íŒ¨í„´
    theory_pattern = r'((?:[A-Z][a-z]*\s*)*(?:ì´ë¡ |ë…íŠ¸ë¦°|ì „ëµ|doctrine|theory|strategy))'
    theory_matches = re.finditer(theory_pattern, analysis)
    for match in theory_matches:
        theory = match.group(1).strip()
        references.append({
            "type": "theory",
            "name": theory,
            "context": analysis[max(0, match.start() - 30):match.end() + 50]
        })
    
    return references

def create_military_citation_list(source_summaries: List[Dict[str, Any]]) -> str:
    """ì†ŒìŠ¤ì—ì„œ êµ°ì‚¬/êµ­ì œì •ì¹˜ ê´€ë ¨ ì¸ìš© ëª©ë¡ ìƒì„±"""
    citations = []
    
    for source in source_summaries:
        # ì†ŒìŠ¤ë³„ ë¶„ì„ì—ì„œ ì¶œì²˜ ì •ë³´ ì¶”ì¶œ ì‹œë„
        analysis = source["analysis"]
        
        # ì €ìëª… ì¶”ì¶œ ì‹œë„
        author_match = re.search(r'ì €ì(?:ëŠ”|ì˜|:|ì€)?\s*([^,.]+)', analysis)
        author = author_match.group(1) if author_match else "Unknown"
        
        # ì œëª© ì¶”ì¶œ ì‹œë„
        title_match = re.search(r'ì œëª©(?:ì€|ëŠ”|:|ì´)?\s*"?([^",.]+)"?', analysis)
        title = title_match.group(1) if title_match else f"Source #{source['index']}"
        
        # ì—°ë„ ì¶”ì¶œ ì‹œë„
        year_match = re.search(r'(19|20)\d{2}ë…„', analysis)
        year = year_match.group(0) if year_match else ""
        
        # ê¸°ê´€ ì¶”ì¶œ ì‹œë„
        institution_match = re.search(r'(?:ê¸°ê´€|ì¶œì²˜|ë°œí–‰ì²˜|ì¶œíŒì‚¬)(?:ëŠ”|ì˜|:|ì€)?\s*([^,.]+)', analysis)
        institution = institution_match.group(1) if institution_match else ""
        
        citation = f"{author}. {title}. {institution} {year}".strip()
        if citation.endswith('.'):
            citation = citation[:-1]
        
        citations.append(citation)
    
    return "\n".join(citations)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    test_texts = [
        "ì´ê²ƒì€ ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë¶í•œì˜ í•µë¬´ê¸° ê°œë°œ í”„ë¡œê·¸ë¨ì— ê´€í•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
        "ì´ê²ƒì€ ë‘ ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë¯¸êµ­ê³¼ ì¤‘êµ­ì˜ êµ°ì‚¬ì  ê¸´ì¥ ê´€ê³„ì— ê´€í•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    ]
    
    result = advanced_summarize_texts(
        test_texts, 
        "ë™ë¶ì•„ì‹œì•„ ì•ˆë³´ ì •ì„¸", 
        "ì„œë¡ -ë³¸ë¡ -ê²°ë¡ ",
        style="military_expert"
    )
    
    print("\nìµœì¢… ìŠ¤í¬ë¦½íŠ¸ ì¼ë¶€:")
    print(result[:500] + "..." if len(result) > 500 else result)