import os
import re
import time
import json
import logging
from typing import Dict, Optional, Tuple, List, Any, Union
from functools import lru_cache
import concurrent.futures
from urllib.parse import urlparse, parse_qs
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¸ì…˜ ìƒì„± ë° ì¬ì‹œë„ ì„¤ì •
def create_session() -> requests.Session:
    """í–¥ìƒëœ ì¬ì‹œë„ ë¡œì§ì„ ê°€ì§„ ìš”ì²­ ì„¸ì…˜ ìƒì„±"""
    session = requests.Session()
    retry_strategy = Retry(
        total=3,
        backoff_factor=0.5,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session

# ê¸°ë³¸ ì„¸ì…˜ ìƒì„±
session = create_session()

# API í˜¸ì¶œ ì¬ì‹œë„ ìœ í‹¸ë¦¬í‹°
def api_call_with_retry(func, *args, max_retries=3, **kwargs):
    """API í˜¸ì¶œ í•¨ìˆ˜ì— ì¬ì‹œë„ ë¡œì§ ì¶”ê°€"""
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if attempt == max_retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„ì˜€ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
                raise
            
            # ì§€ìˆ˜ ë°±ì˜¤í”„ (1ì´ˆ, 2ì´ˆ, 4ì´ˆ...)
            delay = 1 * (2 ** attempt)
            logger.warning(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ ({attempt+1}/{max_retries}), {delay}ì´ˆ í›„ ì¬ì‹œë„: {str(e)}")
            time.sleep(delay)

@lru_cache(maxsize=32)
def parse_youtube(url: str, output_dir: str = "temp_youtube") -> str:
    """
    ìœ íŠœë¸Œ ì˜ìƒ URLì—ì„œ ì½˜í…ì¸  ì¶”ì¶œ - ìºì‹± ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”
    
    1. ìë§‰ì´ ìˆìœ¼ë©´ ìë§‰ ì¶”ì¶œ
    2. ìë§‰ì´ ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ í›„ Whisperë¡œ ìŒì„± ì¸ì‹
    3. ì„¤ëª…, ì œëª© ë“± ë©”íƒ€ë°ì´í„°ë„ í•¨ê»˜ ì¶”ì¶œ
    
    Args:
        url: ìœ íŠœë¸Œ ì˜ìƒ URL
        output_dir: ì„ì‹œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš©
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # ë¹„ë””ì˜¤ ID ì¶”ì¶œ
    video_id = extract_video_id(url)
    if not video_id:
        logger.error(f"âŒ ìœ íš¨í•œ YouTube ë¹„ë””ì˜¤ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {url}")
        return f"ì˜¤ë¥˜: ìœ íš¨í•œ YouTube URLì´ ì•„ë‹™ë‹ˆë‹¤ ({url})"
    
    try:
        logger.info(f"ğŸ¬ ìœ íŠœë¸Œ ì˜ìƒ ë¶„ì„ ì¤‘: {url} (ID: {video_id})")
        
        # ìºì‹œ íŒŒì¼ ê²½ë¡œ
        cache_path = os.path.join(output_dir, f"{video_id}_content.txt")
        
        # ìºì‹œ íŒŒì¼ì´ ìˆìœ¼ë©´ ì½ì–´ì„œ ë°˜í™˜
        if os.path.exists(cache_path):
            logger.info(f"ğŸ“‚ ìºì‹œì—ì„œ ìœ íŠœë¸Œ ì½˜í…ì¸  ë¡œë“œ: {video_id}")
            with open(cache_path, "r", encoding="utf-8") as f:
                return f.read()
        
        # ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        metadata = get_youtube_metadata(url, video_id)
        
        # ë©”íƒ€ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        meta_text = f"ì œëª©: {metadata['title']}\n"
        meta_text += f"ì±„ë„: {metadata['author']}\n"
        meta_text += f"ê²Œì‹œì¼: {metadata['publish_date']}\n"
        meta_text += f"ì¡°íšŒìˆ˜: {metadata['views']:,}\n\n"
        meta_text += f"ì„¤ëª…:\n{metadata['description']}\n\n"
        
        # ìë§‰ ì²˜ë¦¬ ì‹œë„
        transcript_text = ""
        has_transcript = False
        
        # 1. YouTubeì—ì„œ ì§ì ‘ ìë§‰ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        try:
            transcript_text = get_youtube_transcript(video_id)
            if transcript_text:
                has_transcript = True
                logger.info("âœ… YouTube ìë§‰ ì¶”ì¶œ ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ YouTube ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        # 2. ìë§‰ì´ ì—†ëŠ” ê²½ìš° ìŒì„± ì¸ì‹ ìˆ˜í–‰
        if not has_transcript:
            logger.info("ğŸ”Š ìë§‰ì´ ì—†ì–´ ìŒì„± ì¸ì‹ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            
            # ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
            audio_path = os.path.join(output_dir, f"{video_id}.mp3")
            
            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if not os.path.exists(audio_path):
                download_youtube_audio(url, video_id, audio_path)
            else:
                logger.info(f"âœ… ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚¬ìš©: {audio_path}")
            
            # Whisperë¡œ ìŒì„± ì¸ì‹
            if os.path.exists(audio_path):
                transcript_text = transcribe_with_whisper(audio_path)
                if transcript_text:
                    has_transcript = True
                    logger.info("âœ… Whisper ìŒì„± ì¸ì‹ ì„±ê³µ")
            else:
                logger.error(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        
        # ìµœì¢… ê²°ê³¼ ì¡°í•©
        if has_transcript:
            result = meta_text + "ë‚´ìš© ìŠ¤í¬ë¦½íŠ¸:\n" + transcript_text
        else:
            result = meta_text + "ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        # ê²°ê³¼ ìºì‹±
        with open(cache_path, "w", encoding="utf-8") as f:
            f.write(result)
            
        logger.info(f"âœ… ìœ íŠœë¸Œ ì½˜í…ì¸  ì¶”ì¶œ ì™„ë£Œ: {metadata['title']}")
        return result
            
    except Exception as e:
        logger.error(f"âŒ ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return f"ìœ íŠœë¸Œ ì˜ìƒ ì²˜ë¦¬ ì‹¤íŒ¨ ({url}): {str(e)}"

def download_youtube_audio(url: str, video_id: str, output_path: str) -> bool:
    """ìœ íŠœë¸Œ ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ"""
    try:
        # ë™ì  ì„í¬íŠ¸ - í•„ìš”í•  ë•Œë§Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
        from pytube import YouTube
        
        yt = YouTube(url)
        audio_stream = yt.streams.filter(only_audio=True).first()
        
        if not audio_stream:
            logger.error("âŒ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
            
        logger.info(f"ğŸ”½ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘... ({yt.title})")
        audio_stream.download(filename=output_path)
        logger.info(f"âœ… ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return False

def get_youtube_metadata(url: str, video_id: str) -> Dict[str, Any]:
    """ìœ íŠœë¸Œ ì˜ìƒ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        # pytube ì‚¬ìš© ì‹œë„
        from pytube import YouTube
        
        yt = YouTube(url)
        return {
            "title": yt.title or "ì œëª© ì—†ìŒ",
            "author": yt.author or "ì±„ë„ ì •ë³´ ì—†ìŒ",
            "publish_date": str(yt.publish_date) if yt.publish_date else "ì•Œ ìˆ˜ ì—†ìŒ",
            "views": yt.views or 0,
            "description": yt.description or "ì„¤ëª… ì—†ìŒ"
        }
    except:
        # Web íŒŒì‹± ëŒ€ì²´ ë°©ë²•
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            response = session.get(f"https://www.youtube.com/watch?v={video_id}", headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ì œëª© ì¶”ì¶œ
            title_elem = soup.find('meta', property='og:title')
            title = title_elem['content'] if title_elem else "ì œëª© ì—†ìŒ"
            
            # ì±„ë„ëª… ì¶”ì¶œ
            author_elem = soup.find('link', itemprop='name')
            author = author_elem['content'] if author_elem else "ì±„ë„ ì •ë³´ ì—†ìŒ"
            
            # ì„¤ëª… ì¶”ì¶œ
            desc_elem = soup.find('meta', property='og:description')
            description = desc_elem['content'] if desc_elem else "ì„¤ëª… ì—†ìŒ"
            
            return {
                "title": title,
                "author": author,
                "publish_date": "ì•Œ ìˆ˜ ì—†ìŒ",
                "views": 0,
                "description": description
            }
        except Exception as e:
            logger.error(f"âŒ ì›¹ íŒŒì‹±ì„ í†µí•œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "title": f"YouTube ë¹„ë””ì˜¤ {video_id}",
                "author": "ì±„ë„ ì •ë³´ ì—†ìŒ",
                "publish_date": "ì•Œ ìˆ˜ ì—†ìŒ",
                "views": 0,
                "description": "ì„¤ëª…ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

@lru_cache(maxsize=64)
def get_youtube_transcript(video_id: str) -> str:
    """
    ìœ íŠœë¸Œì—ì„œ ìë§‰ ì¶”ì¶œ ì‹œë„ (ì—¬ëŸ¬ ë°©ë²• ì‚¬ìš©)
    
    1. youtube_transcript_api ì‚¬ìš©
    2. ì‹¤íŒ¨ ì‹œ ì›¹ íŒŒì‹± ì‹œë„
    """
    try:
        logger.info(f"ğŸ”¤ ìë§‰ ì¶”ì¶œ ì‹œë„: {video_id}")
        
        # ë°©ë²• 1: youtube_transcript_api ì‚¬ìš©
        try:
            from youtube_transcript_api import YouTubeTranscriptApi
            
            # í•œêµ­ì–´ ìë§‰ ìš°ì„ , ì—†ìœ¼ë©´ ì˜ì–´, ê·¸ ì™¸ ì–¸ì–´ ìˆœìœ¼ë¡œ ì‹œë„
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            transcript_data = None
            
            # ì–¸ì–´ ìš°ì„ ìˆœìœ„
            preferred_langs = ['ko', 'en', 'ja', 'zh-Hans', 'zh-Hant', 'es', 'fr', 'de']
            
            # ìˆ˜ë™ ìë§‰ ë¨¼ì € ì‹œë„
            try:
                for lang in preferred_langs:
                    try:
                        transcript = transcript_list.find_manually_created_transcript([lang])
                        transcript_data = transcript.fetch()
                        logger.info(f"âœ… ìˆ˜ë™ ìë§‰ ì°¾ìŒ (ì–¸ì–´: {lang})")
                        break
                    except:
                        continue
            except:
                pass
                
            # ìˆ˜ë™ ìë§‰ ì‹¤íŒ¨ ì‹œ ìë™ ìƒì„± ìë§‰ ì‹œë„
            if not transcript_data:
                try:
                    for lang in preferred_langs:
                        try:
                            transcript = transcript_list.find_generated_transcript([lang])
                            transcript_data = transcript.fetch()
                            logger.info(f"âœ… ìë™ ìƒì„± ìë§‰ ì°¾ìŒ (ì–¸ì–´: {lang})")
                            break
                        except:
                            continue
                except:
                    pass
            
            # ìœ„ ë°©ë²• ì‹¤íŒ¨ ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ìë§‰ ì‹œë„
            if not transcript_data:
                try:
                    transcript = next(iter(transcript_list._manually_created_transcripts.values()))
                    transcript_data = transcript.fetch()
                    logger.info(f"âœ… ê¸°íƒ€ ìˆ˜ë™ ìë§‰ ì°¾ìŒ (ì–¸ì–´: {transcript.language_code})")
                except:
                    try:
                        transcript = next(iter(transcript_list._generated_transcripts.values()))
                        transcript_data = transcript.fetch()
                        logger.info(f"âœ… ê¸°íƒ€ ìë™ ìë§‰ ì°¾ìŒ (ì–¸ì–´: {transcript.language_code})")
                    except:
                        pass
            
            # ìë§‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²˜ë¦¬
            if transcript_data:
                # ì‹œê°„ ì •ë³´ í¬í•¨ ì—¬ë¶€ ê²°ì • (ê¸°ë³¸: í¬í•¨í•˜ì§€ ì•ŠìŒ)
                include_timestamps = False
                
                if include_timestamps:
                    # ì‹œê°„ ì •ë³´ë¥¼ í¬í•¨í•œ í˜•ì‹
                    texts = []
                    for item in transcript_data:
                        start_time = format_timestamp(item['start'])
                        text = item['text'].strip()
                        texts.append(f"[{start_time}] {text}")
                    return '\n'.join(texts)
                else:
                    # ì‹œê°„ ì •ë³´ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ
                    texts = [item['text'].strip() for item in transcript_data]
                    
                    # ìë§‰ í›„ì²˜ë¦¬ - ë¬¸ì¥ ì™„ì„± ë° ì •ë¦¬
                    processed_text = process_transcript_text(texts)
                    return processed_text
        
        except ImportError:
            logger.warning("âš ï¸ youtube_transcript_api ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›¹ íŒŒì‹±ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        except Exception as e:
            logger.warning(f"âš ï¸ youtube_transcript_apië¡œ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 2: ì›¹ í˜ì´ì§€ íŒŒì‹± ì‹œë„
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = session.get(f"https://www.youtube.com/watch?v={video_id}", headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ìë§‰ ë°ì´í„° ì°¾ê¸° (ë³µì¡í•˜ê³  ë³€ê²½ ê°€ëŠ¥ì„± ë†’ìŒ)
            scripts = soup.find_all('script')
            transcript_text = ""
            
            for script in scripts:
                if script.string and '"captionTracks"' in script.string:
                    # ìë§‰ URL ì¶”ì¶œ ì‹œë„
                    caption_match = re.search(r'"captionTracks":\s*(\[.*?\])', script.string)
                    if caption_match:
                        captions_data = json.loads(caption_match.group(1))
                        for item in captions_data:
                            if 'baseUrl' in item:
                                caption_url = item['baseUrl']
                                caption_response = session.get(caption_url)
                                
                                # XML íŒŒì‹± (ê°„ì†Œí™” ë²„ì „)
                                caption_soup = BeautifulSoup(caption_response.text, 'xml')
                                texts = [text.get_text() for text in caption_soup.find_all('text')]
                                transcript_text = '\n'.join(texts)
                                
                                # ìë§‰ í›„ì²˜ë¦¬
                                transcript_text = process_transcript_text(texts)
                                break
                        if transcript_text:
                            break
            
            if transcript_text:
                logger.info("âœ… ì›¹ íŒŒì‹±ì„ í†µí•´ ìë§‰ ì¶”ì¶œ ì„±ê³µ")
                return transcript_text
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì›¹ íŒŒì‹±ì„ í†µí•œ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
        logger.warning("âŒ ëª¨ë“  ìë§‰ ì¶”ì¶œ ë°©ë²• ì‹¤íŒ¨")
        return ""
        
    except Exception as e:
        logger.error(f"âŒ ìë§‰ ì¶”ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
        return ""

def process_transcript_text(texts: List[str]) -> str:
    """ìë§‰ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ - ë¬¸ì¥ ì™„ì„± ë° í¬ë§·íŒ…"""
    if not texts:
        return ""
    
    # ë¬¸ì¥ ì¡°í•©
    combined_text = " ".join(texts)
    
    # ì¤‘ë³µ ê³µë°± ì œê±°
    combined_text = re.sub(r'\s+', ' ', combined_text)
    
    # ë¬¸ì¥ êµ¬ë¶„
    sentences = re.split(r'(?<=[.!?])\s+', combined_text)
    
    # ê° ë¬¸ì¥ ì²« ê¸€ì ëŒ€ë¬¸ìë¡œ ë³€í™˜
    sentences = [s[0].upper() + s[1:] if s else s for s in sentences]
    
    # ê²°ê³¼ ì¡°í•©
    result = "\n".join(sentences)
    
    return result

def transcribe_with_whisper(audio_path: str, model_size: str = "base") -> str:
    """Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ ìŒì„± ì¸ì‹"""
    try:
        logger.info(f"ğŸ¤ Whisper ìŒì„± ì¸ì‹ ì¤‘... (ëª¨ë¸: {model_size})")
        
        # ëª¨ë¸ ìˆëŠ”ì§€ í™•ì¸
        try:
            import whisper
        except ImportError:
            logger.error("âŒ Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return "ìŒì„± ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬(Whisper)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # Whisper ëª¨ë¸ ë¡œë“œ
        model = whisper.load_model(model_size)
        
        # ìŒì„± ì¸ì‹ ìˆ˜í–‰
        def run_whisper():
            result = model.transcribe(
                audio_path,
                language=None,  # ìë™ ê°ì§€
                task="transcribe",
                verbose=False
            )
            return result["text"]
            
        # ì¬ì‹œë„ ë¡œì§ ì ìš©
        transcription = api_call_with_retry(run_whisper)
        
        return transcription
        
    except Exception as e:
        logger.error(f"âŒ Whisper ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
        return f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}"

def extract_video_id(url: str) -> Optional[str]:
    """ìœ íŠœë¸Œ URLì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ - ë‹¤ì–‘í•œ URL í˜•ì‹ ì§€ì›"""
    if not url:
        return None
        
    # URL íŒŒì‹±
    parsed_url = urlparse(url)
    
    # youtu.be ë§í¬ (ë‹¨ì¶• URL)
    if parsed_url.netloc == 'youtu.be':
        return parsed_url.path.strip('/')
    
    # ì¼ë°˜ youtube.com ë§í¬
    if parsed_url.netloc in ('www.youtube.com', 'youtube.com'):
        # watch í˜ì´ì§€
        if parsed_url.path == '/watch':
            query = parse_qs(parsed_url.query)
            if 'v' in query:
                return query['v'][0]
        
        # shorts í˜ì´ì§€
        elif '/shorts/' in parsed_url.path:
            parts = parsed_url.path.split('/')
            if len(parts) >= 3:
                return parts[2]
        
        # embed í˜ì´ì§€
        elif parsed_url.path.startswith('/embed/'):
            return parsed_url.path.split('/')[2]
    
    # ì •ê·œì‹ìœ¼ë¡œ ë§ˆì§€ë§‰ ì‹œë„
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/|youtube\.com\/shorts\/)([a-zA-Z0-9_-]{11})',
        r'youtube\.com\/watch\?.*?v=([a-zA-Z0-9_-]{11})',
        r'youtube\.com\/v\/([a-zA-Z0-9_-]{11})',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    
    return None

def format_timestamp(seconds: float) -> str:
    """ì´ˆë¥¼ mm:ss í˜•ì‹ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë³€í™˜"""
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes:02d}:{secs:02d}"

def cleanup_temp_files(output_dir: str, video_id: str) -> None:
    """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    try:
        audio_path = os.path.join(output_dir, f"{video_id}.mp3")
        if os.path.exists(audio_path):
            os.remove(audio_path)
            logger.info(f"âœ… ì„ì‹œ íŒŒì¼ ì‚­ì œ: {audio_path}")
    except Exception as e:
        logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    test_url = "https://www.youtube.com/watch?v=dQw4w9WgXcQ"  # ìƒ˜í”Œ ì˜ìƒ
    logger.info(f"í…ŒìŠ¤íŠ¸ URL: {test_url}")
    
    video_id = extract_video_id(test_url)
    logger.info(f"ì¶”ì¶œëœ ë¹„ë””ì˜¤ ID: {video_id}")
    
    content = parse_youtube(test_url)
    logger.info("\n=== ì¶”ì¶œëœ ì½˜í…ì¸  ì¼ë¶€ ===")
    print(content[:500] + "..." if len(content) > 500 else content)
    
    # ì¶”ê°€ URL í¬ë§· í…ŒìŠ¤íŠ¸
    test_urls = [
        "https://youtu.be/dQw4w9WgXcQ",
        "https://www.youtube.com/shorts/dQw4w9WgXcQ",
        "https://www.youtube.com/embed/dQw4w9WgXcQ"
    ]
    
    logger.info("\n=== ë‹¤ì–‘í•œ URL í¬ë§· í…ŒìŠ¤íŠ¸ ===")
    for url in test_urls:
        vid_id = extract_video_id(url)
        logger.info(f"URL: {url} -> ë¹„ë””ì˜¤ ID: {vid_id}")