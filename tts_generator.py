import os
import requests
import time
import re
import json
import logging
from typing import Optional, List, Dict, Any, Tuple
from dotenv import load_dotenv
from functools import lru_cache
import concurrent.futures
import io
from pathlib import Path
import threading
import random

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
api_key = os.getenv("ELEVENLABS_API_KEY")

# ì „ì—­ ì„¤ì •
MAX_RETRIES = 3
BASE_RETRY_DELAY = 1  # ì´ˆ ë‹¨ìœ„
MAX_CHUNK_SIZE = 4000  # ìµœëŒ€ ì²­í¬ í¬ê¸° (ë¬¸ì)
MAX_WORKERS = 3  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜

# TTS API í˜¸ì¶œ ì„¸ë§ˆí¬ì–´ ì¶”ê°€ - ìŒì„± ìƒì„±ì€ ë¬´ê±°ìš´ ì‘ì—…ì´ë¯€ë¡œ ì œí•œ ê°•í™”
tts_semaphore = threading.Semaphore(2)  # ìµœëŒ€ 2ê°œ ë™ì‹œ TTS ìš”ì²­


def api_call_with_retry(func, *args, max_retries=MAX_RETRIES, **kwargs):
    """
    API í˜¸ì¶œ í•¨ìˆ˜ë¥¼ ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ ê°ì‹¸ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    ì§€ìˆ˜ ë°±ì˜¤í”„ ì „ëµ ì‚¬ìš©
    
    Args:
        func: í˜¸ì¶œí•  í•¨ìˆ˜
        *args, **kwargs: í•¨ìˆ˜ì— ì „ë‹¬í•  ì¸ìë“¤
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        
    Returns:
        í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼
    """
    with tts_semaphore:
        for attempt in range(max_retries):
            try:
                # ì²« ë²ˆì§¸ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€
                if attempt > 0:
                    # ì§€ìˆ˜ ë°±ì˜¤í”„ + ë¬´ì‘ìœ„ì„±(jitter) ì¶”ê°€
                    base_delay = BASE_RETRY_DELAY * (2 ** attempt)
                    jitter = random.uniform(0, 0.5 * base_delay)
                    delay = base_delay + jitter
                    logger.warning(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ ({attempt+1}/{max_retries}), {delay:.2f}ì´ˆ í›„ ì¬ì‹œë„")
                    time.sleep(delay)
                
                return func(*args, **kwargs)
            except Exception as e:
                if attempt == max_retries - 1:
                    # ë§ˆì§€ë§‰ ì‹œë„ì˜€ë‹¤ë©´ ì˜ˆì™¸ ë°œìƒ
                    raise
                
                logger.warning(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ ({attempt+1}/{max_retries}): {str(e)}")

def resolve_voice_id(voice_id: str) -> str:
    """ìŒì„± ì´ë¦„ì„ UUIDë¡œ ë³€í™˜í•˜ê±°ë‚˜ UUIDë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜"""
    voice_id_map = {
        'wyatt': "YXpFCvM1S3JbWEJhoskW",
        'james': "EkK5I93UQWFDigLMpZcX",
        'brian': "nPczCjzI2devNBz1zQrb",
    }
    user_input_voice = voice_id.lower()
    return voice_id_map.get(user_input_voice, voice_id)

def generate_tts_elevenlabs(
    script: str, 
    voice_id: str = "YXpFCvM1S3JbWEJhoskW", 
    output_dir: str = "output_audio", 
    max_chunk_size: int = MAX_CHUNK_SIZE,
    filename_prefix: str = "speech",
    model_id: str = "eleven_multilingual_v2",
    stability: float = 0.4,
    similarity_boost: float = 0.75,
    style: float = 0.15,
    use_parallel: bool = True,
    optimize_streaming_latency: Optional[int] = None
) -> str:
    """
    ìŠ¤í¬ë¦½íŠ¸ë¥¼ Eleven Labs TTSë¡œ ë³€í™˜í•˜ì—¬ MP3 íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ê¸´ ìŠ¤í¬ë¦½íŠ¸ì˜ ê²½ìš° ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ ì²˜ë¦¬í•˜ê³  ê²°í•©í•©ë‹ˆë‹¤.
    
    Args:
        script: ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice_id: Eleven Labs ìŒì„± ID (ê¸°ë³¸ê°’: Adam - ìì—°ìŠ¤ëŸ¬ìš´ ë‚¨ì„± ì˜ì–´ ìŒì„±)
        output_dir: ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
        max_chunk_size: ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜
        filename_prefix: ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì ‘ë‘ì‚¬
        model_id: Eleven Labs ëª¨ë¸ ID
        stability: ìŒì„± ì•ˆì •ì„± (0.0~1.0)
        similarity_boost: ì›ë³¸ ìŒì„±ê³¼ì˜ ìœ ì‚¬ë„ í–¥ìƒ ì •ë„ (0.0~1.0)
        style: ìŠ¤íƒ€ì¼ ê°•ë„ (0.0~1.0)
        use_parallel: ë³‘ë ¬ ì²˜ë¦¬ ì‚¬ìš© ì—¬ë¶€
        optimize_streaming_latency: ìŠ¤íŠ¸ë¦¬ë° ì§€ì—° ìµœì í™” (0~4, None=ì‚¬ìš©ì•ˆí•¨)
        
    Returns:
        ì €ì¥ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    """
    if not api_key:
        logger.error("âŒ Eleven Labs API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— ELEVENLABS_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return ""
    
    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)

        # ìŒì„± ìš”ì†Œë§Œ ì¶”ì¶œ (ì˜ìƒ ì§€ì‹œì‚¬í•­ ì œì™¸)
        speech_script = extract_speech_parts(script)
        
        # TTSë¥¼ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ ì „ì²˜ë¦¬
        processed_script = process_script_for_tts(speech_script)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ëª… ìƒì„±
        timestamp = int(time.time())
        base_filename = f"{filename_prefix}_{timestamp}"
        output_path = os.path.join(output_dir, f"{base_filename}.mp3")
        
        # ìŠ¤í¬ë¦½íŠ¸ ì²­í¬ ë¶„ë¦¬
        chunks = split_script_into_chunks(processed_script, max_chunk_size)
        total_chunks = len(chunks)
        
        logger.info(f"ğŸ”Š Eleven Labs TTS ìƒì„± ì‹œì‘ (ìŒì„±: {get_voice_name(voice_id)}, ì²­í¬: {total_chunks}ê°œ)")
        
        if total_chunks == 1:
            # ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬
            try:
                logger.info(f"ğŸ¤ Eleven Labs TTS ìŒì„± ìƒì„± ì¤‘...")
                audio_data = generate_single_audio_chunk(chunks[0], voice_id, model_id, stability, similarity_boost, style, optimize_streaming_latency)
                
                if audio_data:
                    with open(output_path, "wb") as f:
                        f.write(audio_data)
                    logger.info(f"âœ… ìŒì„± ìƒì„± ì™„ë£Œ: {output_path}")
                    return output_path
                else:
                    logger.error("âŒ Eleven Labs TTS ìƒì„± ì‹¤íŒ¨")
                    return ""
            except Exception as e:
                logger.error(f"âŒ Eleven Labs TTS ìƒì„± ì‹¤íŒ¨: {e}")
                return ""
        else:
            # ë‹¤ì¤‘ ì²­í¬ ì²˜ë¦¬
            logger.info(f"ğŸ“Š ìŠ¤í¬ë¦½íŠ¸ê°€ {total_chunks}ê°œ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            if use_parallel and total_chunks > 1:
                # ë³‘ë ¬ ì²˜ë¦¬
                chunk_paths = generate_audio_chunks_parallel(
                    chunks, voice_id, model_id, stability, similarity_boost, style,
                    optimize_streaming_latency, base_filename, output_dir
                )
            else:
                # ìˆœì°¨ ì²˜ë¦¬
                chunk_paths = generate_audio_chunks_sequential(
                    chunks, voice_id, model_id, stability, similarity_boost, style,
                    optimize_streaming_latency, base_filename, output_dir
                )
            
            if not chunk_paths:
                logger.error("âŒ ëª¨ë“  ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨")
                return ""
            
            # ì˜¤ë””ì˜¤ ì²­í¬ ê²°í•©
            try:
                combined_path = combine_audio_chunks(chunk_paths, output_path)
                if combined_path:
                    logger.info(f"âœ… ì „ì²´ ìŒì„± íŒŒì¼ ê²°í•© ì™„ë£Œ: {combined_path}")
                    return combined_path
                else:
                    # ê²°í•© ì‹¤íŒ¨ì‹œ ì²« ë²ˆì§¸ ì²­í¬ ë°˜í™˜
                    logger.warning("âš ï¸ ì²­í¬ ê²°í•© ì‹¤íŒ¨, ì²« ë²ˆì§¸ ì²­í¬ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                    return chunk_paths[0]
            except Exception as e:
                logger.error(f"âŒ ì˜¤ë””ì˜¤ ì²­í¬ ê²°í•© ì‹¤íŒ¨: {e}")
                return chunk_paths[0] if chunk_paths else ""
    
    except Exception as e:
        logger.error(f"âŒ TTS ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
        return ""

def generate_single_audio_chunk(
    text: str, 
    voice_id: str,
    model_id: str = "eleven_multilingual_v2",
    stability: float = 0.4,
    similarity_boost: float = 0.75,
    style: float = 0.15,
    optimize_streaming_latency: Optional[int] = None
) -> Optional[bytes]:
    """
    ë‹¨ì¼ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice_id: Eleven Labs ìŒì„± ID
        model_id: ì‚¬ìš©í•  ëª¨ë¸ ID
        stability: ìŒì„± ì•ˆì •ì„± (0.0~1.0)
        similarity_boost: ì›ë³¸ ìŒì„±ê³¼ì˜ ìœ ì‚¬ë„ í–¥ìƒ ì •ë„ (0.0~1.0)
        style: ìŠ¤íƒ€ì¼ ê°•ë„ (0.0~1.0)
        optimize_streaming_latency: ìŠ¤íŠ¸ë¦¬ë° ì§€ì—° ìµœì í™” (0~4, None=ì‚¬ìš©ì•ˆí•¨)
        
    Returns:
        ì˜¤ë””ì˜¤ ë°ì´í„° ë°”ì´íŠ¸ ë˜ëŠ” None
    """
    def make_tts_request():
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
        
        headers = {
            "Accept": "audio/mpeg",
            "Content-Type": "application/json",
            "xi-api-key": api_key
        }
        
        data = {
            "text": text,
            "model_id": model_id,
            "voice_settings": {
                "stability": stability,
                "similarity_boost": similarity_boost,
                "style": style,
                "use_speaker_boost": True
            }
        }
        
        # ìŠ¤íŠ¸ë¦¬ë° ì§€ì—° ìµœì í™” ì„¤ì • ì¶”ê°€ (ê¸°ëŠ¥ ì‚¬ìš© ì‹œ)
        if optimize_streaming_latency is not None:
            data["optimize_streaming_latency"] = optimize_streaming_latency
        
        response = requests.post(url, json=data, headers=headers)
        
        if response.status_code == 200:
            return response.content
        else:
            error_msg = f"Eleven Labs API ì˜¤ë¥˜ ({response.status_code}): "
            try:
                error_data = response.json()
                error_msg += json.dumps(error_data)
            except:
                error_msg += response.text
            
            logger.error(error_msg)
            raise Exception(error_msg)
    
    # ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ API í˜¸ì¶œ
    return api_call_with_retry(make_tts_request)

def generate_audio_chunks_parallel(
    chunks: List[str],
    voice_id: str,
    model_id: str,
    stability: float,
    similarity_boost: float,
    style: float,
    optimize_streaming_latency: Optional[int],
    base_filename: str,
    output_dir: str
) -> List[str]:
    """
    í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³‘ë ¬ë¡œ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜
    
    Args:
        chunks: í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        voice_id: Eleven Labs ìŒì„± ID
        model_id: ì‚¬ìš©í•  ëª¨ë¸ ID
        stability: ìŒì„± ì•ˆì •ì„±
        similarity_boost: ì›ë³¸ ìŒì„±ê³¼ì˜ ìœ ì‚¬ë„
        style: ìŠ¤íƒ€ì¼ ê°•ë„
        optimize_streaming_latency: ìŠ¤íŠ¸ë¦¬ë° ì§€ì—° ìµœì í™”
        base_filename: ê¸°ë³¸ íŒŒì¼ ì´ë¦„
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    chunk_paths = []
    total_chunks = len(chunks)
    logger.info(f"ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬ë¡œ {total_chunks}ê°œ ì²­í¬ ìƒì„± ì¤‘... (ìµœëŒ€ {MAX_WORKERS}ê°œ ì‘ì—…ì)")
    
    # ë³‘ë ¬ ì²˜ë¦¬ í•¨ìˆ˜
    def process_chunk(chunk_data):
        idx, chunk_text = chunk_data
        chunk_filename = f"{base_filename}_part{idx+1}.mp3"
        chunk_path = os.path.join(output_dir, chunk_filename)
        
        try:
            logger.info(f"ğŸ¤ ì²­í¬ {idx+1}/{total_chunks} ìƒì„± ì¤‘ ({len(chunk_text)} ë¬¸ì)")
            audio_data = generate_single_audio_chunk(
                chunk_text, voice_id, model_id, stability, 
                similarity_boost, style, optimize_streaming_latency
            )
            
            if audio_data:
                with open(chunk_path, "wb") as f:
                    f.write(audio_data)
                logger.info(f"âœ… ì²­í¬ {idx+1}/{total_chunks} ìƒì„± ì™„ë£Œ")
                return idx, chunk_path, True
            else:
                logger.error(f"âŒ ì²­í¬ {idx+1}/{total_chunks} ìƒì„± ì‹¤íŒ¨")
                return idx, "", False
        except Exception as e:
            logger.error(f"âŒ ì²­í¬ {idx+1}/{total_chunks} ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return idx, "", False
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=min(MAX_WORKERS, total_chunks)) as executor:
        # ì¼ê´„ ì œì¶œ ëŒ€ì‹  í•˜ë‚˜ì”© ì œì¶œí•˜ê³  ì™„ë£Œë  ë•Œë§ˆë‹¤ ë‹¤ìŒ ì‘ì—… ì œì¶œ
        future_to_idx = {}
        remaining_items = list(enumerate(chunks))
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ ì œì¶œ (ì›Œì»¤ ìˆ˜ë§Œí¼)
        worker_count = min(MAX_WORKERS, total_chunks)
        initial_batch = remaining_items[:worker_count]
        remaining_items = remaining_items[worker_count:]
        
        for item in initial_batch:
            future = executor.submit(process_chunk, item)
            future_to_idx[future] = item[0]
        
        # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬ ë° ìƒˆ ì‘ì—… ì œì¶œ
        while future_to_idx:
            # ì™„ë£Œëœ ì‘ì—… í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
            done, _ = concurrent.futures.wait(
                future_to_idx, 
                return_when=concurrent.futures.FIRST_COMPLETED
            )
            
            for future in done:
                try:
                    idx, path, success = future.result()
                    if success and path:
                        results.append((idx, path))
                    
                    # ìƒˆ ì‘ì—… ì œì¶œ (ë‚¨ì€ í•­ëª©ì´ ìˆëŠ” ê²½ìš°)
                    if remaining_items:
                        new_item = remaining_items.pop(0)
                        new_future = executor.submit(process_chunk, new_item)
                        future_to_idx[new_future] = new_item[0]
                    
                except Exception as e:
                    logger.error(f"âŒ ì²­í¬ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                
                # ì²˜ë¦¬ëœ future ì‚­ì œ
                del future_to_idx[future]
    
    # ê²°ê³¼ ì •ë ¬ (ì›ë˜ ìˆœì„œëŒ€ë¡œ)
    results.sort(key=lambda x: x[0])
    
    # ì„±ê³µí•œ ê²½ë¡œë§Œ í•„í„°ë§
    chunk_paths = [res[1] for res in results if res[2]]
    
    success_count = len(chunk_paths)
    logger.info(f"ğŸ ì²­í¬ ìƒì„± ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {total_chunks - success_count}ê°œ")
    
    return chunk_paths

def generate_audio_chunks_sequential(
    chunks: List[str],
    voice_id: str,
    model_id: str,
    stability: float,
    similarity_boost: float,
    style: float,
    optimize_streaming_latency: Optional[int],
    base_filename: str,
    output_dir: str
) -> List[str]:
    """
    í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜
    
    Args:
        chunks: í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        voice_id: Eleven Labs ìŒì„± ID
        model_id: ì‚¬ìš©í•  ëª¨ë¸ ID
        stability: ìŒì„± ì•ˆì •ì„±
        similarity_boost: ì›ë³¸ ìŒì„±ê³¼ì˜ ìœ ì‚¬ë„
        style: ìŠ¤íƒ€ì¼ ê°•ë„
        optimize_streaming_latency: ìŠ¤íŠ¸ë¦¬ë° ì§€ì—° ìµœì í™”
        base_filename: ê¸°ë³¸ íŒŒì¼ ì´ë¦„
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    chunk_paths = []
    total_chunks = len(chunks)
    
    for i, chunk in enumerate(chunks):
        chunk_filename = f"{base_filename}_part{i+1}.mp3"
        chunk_path = os.path.join(output_dir, chunk_filename)
        
        try:
            logger.info(f"ğŸ¤ ì²­í¬ {i+1}/{total_chunks} ìƒì„± ì¤‘ ({len(chunk)} ë¬¸ì)")
            audio_data = generate_single_audio_chunk(
                chunk, voice_id, model_id, stability, 
                similarity_boost, style, optimize_streaming_latency
            )
            
            if audio_data:
                with open(chunk_path, "wb") as f:
                    f.write(audio_data)
                
                chunk_paths.append(chunk_path)
                logger.info(f"âœ… ì²­í¬ {i+1}/{total_chunks} ìƒì„± ì™„ë£Œ")
            else:
                logger.error(f"âŒ ì²­í¬ {i+1}/{total_chunks} ìƒì„± ì‹¤íŒ¨")
            
            # API ìš”ì²­ ê°„ ê°„ê²© (ë„ˆë¬´ ë§ì€ ìš”ì²­ì„ ë°©ì§€í•˜ê¸° ìœ„í•¨)
            if i < total_chunks - 1:
                time.sleep(0.5)  # Eleven Labs ìš”ì²­ ì œí•œ ê³ ë ¤
            
        except Exception as e:
            logger.error(f"âŒ ì²­í¬ {i+1}/{total_chunks} ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            continue
    
    return chunk_paths

@lru_cache(maxsize=32)
def get_available_voices() -> List[Dict[str, Any]]:
    """
    Eleven Labsì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    ìºì‹±ì„ í†µí•´ ë°˜ë³µ í˜¸ì¶œ ìµœì†Œí™”
    
    Returns:
        ìŒì„± ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    url = "https://api.elevenlabs.io/v1/voices"
    
    headers = {
        "Accept": "application/json",
        "xi-api-key": api_key
    }
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            voices = response.json().get("voices", [])
            return voices
        else:
            logger.warning(f"âš ï¸ Eleven Labs ìŒì„± ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {response.status_code}")
            return []
    except Exception as e:
        logger.error(f"âš ï¸ Eleven Labs API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return []

def get_voice_name(voice_id: str) -> str:
    """
    ìŒì„± IDë¡œ ìŒì„± ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        voice_id: Eleven Labs ìŒì„± ID
        
    Returns:
        ìŒì„± ì´ë¦„ (ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ID ë°˜í™˜)
    """
    # ì¶”ì²œ ìŒì„±ì—ì„œ ë¨¼ì € í™•ì¸
    recommended_voices = list_recommended_voices()
    for name, vid, _ in recommended_voices:
        if vid == voice_id:
            return name
    
    # APIì—ì„œ ê°€ì ¸ì˜¨ ìŒì„± ëª©ë¡ì—ì„œ í™•ì¸
    try:
        voices = get_available_voices()
        for voice in voices:
            if voice.get("voice_id") == voice_id:
                return voice.get("name", voice_id)
    except:
        pass
    
    return voice_id

def combine_audio_chunks(chunk_paths: List[str], output_path: str) -> Optional[str]:
    """
    ì˜¤ë””ì˜¤ ì²­í¬ íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ ê²°í•©
    
    Args:
        chunk_paths: ì²­í¬ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ê²°í•©ëœ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    if not chunk_paths:
        logger.error("âŒ ê²°í•©í•  ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    if len(chunk_paths) == 1:
        # ì²­í¬ê°€ í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ ë³µì‚¬
        import shutil
        shutil.copy(chunk_paths[0], output_path)
        logger.info(f"âœ… ë‹¨ì¼ ì²­í¬ë¥¼ ìµœì¢… íŒŒì¼ë¡œ ë³µì‚¬: {output_path}")
        # ì„ì‹œ íŒŒì¼ ì œê±°
        try:
            os.remove(chunk_paths[0])
        except Exception as e:
            logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì œê±° ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return output_path
    
    try:
        # pydub ì‚¬ìš©
        from pydub import AudioSegment
        
        logger.info(f"ğŸ”„ {len(chunk_paths)}ê°œ ì˜¤ë””ì˜¤ ì²­í¬ ê²°í•© ì¤‘...")
        combined = AudioSegment.empty()
        
        for i, path in enumerate(chunk_paths):
            try:
                audio_segment = AudioSegment.from_mp3(path)
                combined += audio_segment
                logger.info(f"âœ… ì²­í¬ {i+1}/{len(chunk_paths)} ê²°í•© ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ ì²­í¬ {i+1} ê²°í•© ì‹¤íŒ¨: {str(e)}")
        
        # ê²°í•©ëœ ì˜¤ë””ì˜¤ ì €ì¥
        combined.export(output_path, format="mp3")
        
        # ì„ì‹œ íŒŒì¼ ì œê±°
        cleanup_temp_files(chunk_paths)
        
        return output_path
    except ImportError:
        logger.error("âš ï¸ pydub ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì²­í¬ë¥¼ ê²°í•©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        logger.info("âš ï¸ pip install pydubë¥¼ ì‹¤í–‰í•˜ì—¬ pydubë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        # ëŒ€ì²´ ë°©ì•ˆ: ì²« ë²ˆì§¸ ì²­í¬ë§Œ ë°˜í™˜
        if chunk_paths:
            import shutil
            shutil.copy(chunk_paths[0], output_path)
            logger.info(f"âš ï¸ pydub ì—†ìŒ, ì²« ë²ˆì§¸ ì²­í¬ë¥¼ ë³µì‚¬: {output_path}")
            return output_path
        return None
    except Exception as e:
        logger.error(f"âš ï¸ ì²­í¬ ê²°í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def cleanup_temp_files(file_paths: List[str]) -> None:
    """
    ì„ì‹œ íŒŒì¼ ì •ë¦¬
    
    Args:
        file_paths: ì‚­ì œí•  íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    for path in file_paths:
        try:
            if os.path.exists(path):
                os.remove(path)
                logger.debug(f"âœ… ì„ì‹œ íŒŒì¼ ì‚­ì œ: {path}")
        except Exception as e:
            logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def extract_speech_parts(script: str) -> str:
    """
    ì˜ìƒ ì§€ì‹œì‚¬í•­ê³¼ í˜•ì‹ ìš”ì†Œë¥¼ ì œì™¸í•œ ìŒì„± ë¶€ë¶„ë§Œ ì¶”ì¶œ
    
    Args:
        script: ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸
        
    Returns:
        ìŒì„± ë¶€ë¶„ë§Œ í¬í•¨ëœ ìŠ¤í¬ë¦½íŠ¸
    """
    # 1. ê°ì¢… ì˜ìƒ ì§€ì‹œì‚¬í•­ ì œê±° (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
    speech_only = re.sub(r'\[(ì˜ìƒ|Visual|video):\s*.*?\]', '', script, flags=re.IGNORECASE)
    
    # 2. "Narrator: " ì ‘ë‘ì–´ ì œê±°
    speech_only = re.sub(r'(narrator|ë‚´ë ˆì´í„°):\s*', '', speech_only, flags=re.IGNORECASE)
    
    # 3. ë§ˆí¬ë‹¤ìš´ í—¤ë”(###, ---) ì œê±°
    speech_only = re.sub(r'^#{1,6}\s+.*$', '', speech_only, flags=re.MULTILINE)
    speech_only = re.sub(r'^---+$', '', speech_only, flags=re.MULTILINE)
    
    # 4. êµµì€ í…ìŠ¤íŠ¸(**í…ìŠ¤íŠ¸**) ì²˜ë¦¬ - ê°•ì¡°ëŠ” ìœ ì§€í•˜ë˜ ë§ˆí¬ì—… ì œê±°
    speech_only = re.sub(r'\*\*(.*?)\*\*', r'\1', speech_only)
    
    # 5. ìŠ¤í¬ë¦½íŠ¸ ì„¹ì…˜ ì œëª© ì œê±° (Introduction, Development ë“±)
    speech_only = re.sub(r'^\*\*(.*?)\*\*$', '', speech_only, flags=re.MULTILINE)
    
    # 6. ìŠ¤í¬ë¦½íŠ¸ ì¤‘ê°„ì˜ ë‹¤ì¤‘ ë¼ì¸ ì •ë¦¬
    speech_only = re.sub(r'\n{3,}', '\n\n', speech_only)
    
    # 7. ê´„í˜¸ ì•ˆ ì§€ì‹œì‚¬í•­ ì œê±°
    speech_only = re.sub(r'\([^)]*\)', '', speech_only)
    
    # 8. íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
    speech_only = speech_only.replace('"', '"')
    speech_only = speech_only.replace('"', '"')
    speech_only = speech_only.replace('"', '"')
    speech_only = speech_only.replace("'", "'")
    speech_only = speech_only.replace("'", "'")
    speech_only = speech_only.replace("'", "'")
    
    # 9. [End] ë˜ëŠ” [end] íƒœê·¸ ì œê±°
    speech_only = re.sub(r'\[end\]', '', speech_only, flags=re.IGNORECASE)
    
    # 10. ë¹ˆ ì¤„ì´ ì—°ì†ëœ ê²½ìš° í•˜ë‚˜ë¡œ ì •ë¦¬
    speech_only = re.sub(r'\n\s*\n', '\n\n', speech_only)
    
    return speech_only.strip()

def split_script_into_chunks(script: str, max_chars: int = MAX_CHUNK_SIZE) -> List[str]:
    """
    ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜
    ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• ì„ ìœ„í•´ ë¬¸ì¥ ê²½ê³„ ê³ ë ¤
    
    Args:
        script: ë¶„í• í•  ìŠ¤í¬ë¦½íŠ¸
        max_chars: ì²­í¬ ë‹¹ ìµœëŒ€ ë¬¸ì ìˆ˜
        
    Returns:
        ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    sentences = split_into_sentences(script)
    
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        # í•œ ë¬¸ì¥ì´ ìµœëŒ€ í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°
        if len(sentence) > max_chars:
            # í˜„ì¬ ì²­í¬ê°€ ìˆìœ¼ë©´ ë¨¼ì € ì¶”ê°€
            if current_chunk:
                chunks.append(current_chunk)
                current_chunk = ""
            
            # ê¸´ ë¬¸ì¥ ë¶„í•  (êµ¬ë‘ì ì´ë‚˜ ì ‘ì†ì‚¬ ê¸°ì¤€)
            parts = split_long_sentence(sentence, max_chars)
            
            # ë§ˆì§€ë§‰ ë¶€ë¶„ì„ ì œì™¸í•œ ëª¨ë“  ë¶€ë¶„ì„ ì²­í¬ë¡œ ì¶”ê°€
            chunks.extend(parts[:-1])
            
            # ë§ˆì§€ë§‰ ë¶€ë¶„ì€ ë‹¤ìŒ ì²­í¬ì˜ ì‹œì‘ìœ¼ë¡œ ì‚¬ìš©
            current_chunk = parts[-1]
            
        # í˜„ì¬ ì²­í¬ì— ë¬¸ì¥ì„ ì¶”ê°€í–ˆì„ ë•Œ ìµœëŒ€ ë¬¸ì ìˆ˜ë¥¼ ì´ˆê³¼í•˜ëŠ”ì§€ í™•ì¸
        elif len(current_chunk) + len(sentence) + 1 <= max_chars:
            if current_chunk:
                current_chunk += " " + sentence
            else:
                current_chunk = sentence
        else:
            # í˜„ì¬ ì²­í¬ê°€ ì°¨ë©´ chunks ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ê³  ìƒˆ ì²­í¬ ì‹œì‘
            chunks.append(current_chunk)
            current_chunk = sentence
    
    # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks

def split_into_sentences(text: str) -> List[str]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    
    Args:
        text: ë¶„ë¦¬í•  í…ìŠ¤íŠ¸
        
    Returns:
        ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
    """
    # ë¬¸ì¥ ì¢…ë£Œ í‘œì‹œë¡œ ë¶„ë¦¬ (ì˜ì–´/í•œêµ­ì–´ í˜¸í™˜)
    sentence_endings = r'(?<=[.!?])\s+'
    raw_sentences = re.split(sentence_endings, text)
    
    # ë¹ˆ ë¬¸ì¥ ì œê±° ë° ì •ë¦¬
    sentences = [s.strip() for s in raw_sentences if s.strip()]
    
    return sentences

def split_long_sentence(sentence: str, max_length: int) -> List[str]:
    """
    ê¸´ ë¬¸ì¥ì„ ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ ë¶„í• 
    
    Args:
        sentence: ë¶„í• í•  ë¬¸ì¥
        max_length: ê° ë¶€ë¶„ì˜ ìµœëŒ€ ê¸¸ì´
        
    Returns:
        ë¶„í• ëœ ë¶€ë¶„ ë¦¬ìŠ¤íŠ¸
    """
    # êµ¬ë‘ì ì´ë‚˜ ì ‘ì†ì‚¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
    split_points = [
        r'(?<=,)\s+',  # ì‰¼í‘œ í›„
        r'(?<=;)\s+',  # ì„¸ë¯¸ì½œë¡  í›„
        r'(?<=:)\s+',  # ì½œë¡  í›„
        r'\s+(?=and|or|but|because|however|therefore|thus|meanwhile|moreover|furthermore)\s+',  # ì ‘ì†ì‚¬ ì „
        r'\s+-\s+',    # ëŒ€ì‹œ ì£¼ë³€
        r'\s+'         # ê³µë°± (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
    ]
    
    parts = []
    remaining = sentence
    
    while len(remaining) > max_length:
        split_found = False
        
        # ê° ë¶„í•  í¬ì¸íŠ¸ ì‹œë„
        for pattern in split_points:
            # ë‚¨ì€ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ì˜ ëª¨ë“  ë§¤ì¹˜ ì°¾ê¸°
            matches = list(re.finditer(pattern, remaining))
            
            # ìµœëŒ€ ê¸¸ì´ ë‚´ì—ì„œ ê°€ì¥ ë¨¼ ë§¤ì¹˜ ì§€ì  ì°¾ê¸°
            valid_matches = [m for m in matches if m.end() <= max_length]
            
            if valid_matches:
                # ìµœëŒ€ ê¸¸ì´ì— ê°€ê¹Œìš´ ì§€ì ì—ì„œ ë¶„í• 
                split_at = valid_matches[-1].end()
                parts.append(remaining[:split_at].strip())
                remaining = remaining[split_at:].strip()
                split_found = True
                break
        
        # ë¶„í•  ì§€ì ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° (ì ì ˆí•œ êµ¬ë‘ì ì´ë‚˜ ì ‘ì†ì‚¬ê°€ ì—†ìŒ)
        if not split_found:
            # ìµœëŒ€ ê¸¸ì´ì—ì„œ ê°•ì œ ë¶„í• 
            parts.append(remaining[:max_length].strip())
            remaining = remaining[max_length:].strip()
    
    # ë‚¨ì€ ë¶€ë¶„ ì¶”ê°€
    if remaining:
        parts.append(remaining)
    
    return parts

def process_script_for_tts(script: str) -> str:
    """
    TTSë¥¼ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ ì „ì²˜ë¦¬
    
    Args:
        script: ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸
        
    Returns:
        ì „ì²˜ë¦¬ëœ ìŠ¤í¬ë¦½íŠ¸
    """
    # ë°œìŒ ê°œì„ ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    processed = script
    
    # ì¤„ë°”ê¿ˆ ì •ë¦¬
    processed = re.sub(r'\n{2,}', '\n\n', processed)
    
    # ë‹¤ì–‘í•œ ì¸ìš©ë¶€í˜¸ í†µì¼
    processed = processed.replace('"', '"')
    processed = processed.replace('"', '"')
    processed = processed.replace('"', '"')
    processed = processed.replace("'", "'")
    processed = processed.replace("'", "'")
    processed = processed.replace("'", "'")
    
    # TTSê°€ ì˜ ì²˜ë¦¬í•˜ì§€ ëª»í•˜ëŠ” íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
    processed = processed.replace('â€¦', '...')
    processed = processed.replace('â€“', '-')
    processed = processed.replace('â€”', '-')
    
    return processed

def list_recommended_voices() -> List[Tuple[str, str, str]]:
    """
    ì˜ì–´ ì „ë¬¸ê°€ ì½˜í…ì¸ ì— ì í•©í•œ Eleven Labs ìŒì„± ì¶”ì²œ ëª©ë¡
    APIì—ì„œ ê°€ì ¸ì˜¨ ëª©ë¡ê³¼ ë¡œì»¬ ì¶”ì²œ ëª©ë¡ ê²°í•©
    
    Returns:
        (ì´ë¦„, ID, ì„¤ëª…) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ ì¶”ì²œ ëª©ë¡
    default_recommendations = [
        ("Wyatt", "YXpFCvM1S3JbWEJhoskW", "Wise Rustic Cowboy ëª©ì†Œë¦¬"),
        ("James", "EkK5I93UQWFDigLMpZcX", "Husky & Engaging"),
        ("Brian", "nPczCjzI2devNBz1zQrb", "ê¶Œìœ„ ìˆëŠ” ë‚¨ì„± ëª©ì†Œë¦¬, êµ°ì‚¬/ì•ˆë³´ ì „ë¬¸ê°€ ëŠë‚Œ"),
    ]
    
    # API í˜¸ì¶œì´ ê°€ëŠ¥í•˜ë©´ ì „ì²´ ìŒì„± ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹œë„
    try:
        if api_key:
            all_voices = get_available_voices()
            
            # APIì—ì„œ ê°€ì ¸ì˜¨ ìŒì„± ì¤‘ ì˜ì–´ê¶Œ ìŒì„±ë§Œ ì¶”ì¶œ
            english_voices = [
                (voice.get("name"), voice.get("voice_id"), "APIì—ì„œ ê°€ì ¸ì˜¨ ìŒì„±")
                for voice in all_voices
                if "en" in voice.get("labels", {}).get("language", "").lower()
            ]
            
            # ê¸°ë³¸ ì¶”ì²œ ëª©ë¡ê³¼ API ìŒì„± ëª©ë¡ ê²°í•©
            default_ids = [rec[1] for rec in default_recommendations]
            combined_list = list(default_recommendations)
            
            # ê¸°ë³¸ ëª©ë¡ì— ì—†ëŠ” ìŒì„±ë§Œ ì¶”ê°€
            for voice in english_voices:
                if voice[1] not in default_ids:
                    combined_list.append(voice)
            
            return combined_list
    except Exception as e:
        logger.warning(f"âš ï¸ APIì—ì„œ ìŒì„± ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # API í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ëª©ë¡ë§Œ ë°˜í™˜
    return default_recommendations

def batch_generate_tts(
    scripts: List[str], 
    voice_id: str = "pqHfZKP75CvOlQylNhV4", 
    output_dir: str = "output_audio",
    filename_prefix: str = "speech",
    **kwargs
) -> List[str]:
    """
    ì—¬ëŸ¬ ìŠ¤í¬ë¦½íŠ¸ì— ëŒ€í•œ TTS ìƒì„±ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    
    Args:
        scripts: ìŠ¤í¬ë¦½íŠ¸ ë¦¬ìŠ¤íŠ¸
        voice_id: Eleven Labs ìŒì„± ID
        output_dir: ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
        filename_prefix: ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì ‘ë‘ì‚¬
        **kwargs: generate_tts_elevenlabsì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        
    Returns:
        ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    if not scripts:
        logger.warning("âš ï¸ ì²˜ë¦¬í•  ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    if not api_key:
        logger.error("âŒ Eleven Labs API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    os.makedirs(output_dir, exist_ok=True)
    
    total_scripts = len(scripts)
    logger.info(f"ğŸ”„ {total_scripts}ê°œ ìŠ¤í¬ë¦½íŠ¸ TTS ìƒì„± ì‹œì‘")

    # Eleven Labs API ìš”ì²­ ì œí•œ ê³ ë ¤í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
    max_parallel = min(3, total_scripts)  # ìµœëŒ€ 3ê°œ ë™ì‹œ ì²˜ë¦¬
    
    # ë³‘ë ¬ ì²˜ë¦¬ í•¨ìˆ˜
    def process_script(script_data):
        idx, script = script_data
        try:
            # ê° ìŠ¤í¬ë¦½íŠ¸ë§ˆë‹¤ ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
            script_prefix = f"{filename_prefix}_{idx+1}"
            
            logger.info(f"[{idx+1}/{total_scripts}] ìŠ¤í¬ë¦½íŠ¸ TTS ìƒì„± ì¤‘...")
            output_path = generate_tts_elevenlabs(
                script, 
                voice_id=voice_id, 
                output_dir=output_dir,
                filename_prefix=script_prefix,
                **kwargs
            )
            
            if output_path:
                logger.info(f"âœ… [{idx+1}/{total_scripts}] TTS ìƒì„± ì™„ë£Œ: {os.path.basename(output_path)}")
                return idx, output_path, True
            else:
                logger.error(f"âŒ [{idx+1}/{total_scripts}] TTS ìƒì„± ì‹¤íŒ¨")
                return idx, "", False
        except Exception as e:
            logger.error(f"âŒ [{idx+1}/{total_scripts}] TTS ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return idx, "", False
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
    results = []
    
    # Eleven Labs API ìš”ì²­ ì œí•œ ê³ ë ¤í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
    max_parallel = min(3, total_scripts)  # ìµœëŒ€ 3ê°œ ë™ì‹œ ì²˜ë¦¬
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_parallel) as executor:
        # ì¼ê´„ ì œì¶œ ëŒ€ì‹  í•˜ë‚˜ì”© ì œì¶œí•˜ê³  ì™„ë£Œë  ë•Œë§ˆë‹¤ ë‹¤ìŒ ì‘ì—… ì œì¶œ
        future_to_idx = {}
        remaining_items = list(enumerate(scripts))
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ ì œì¶œ (ì›Œì»¤ ìˆ˜ë§Œí¼)
        initial_batch = remaining_items[:max_parallel]
        remaining_items = remaining_items[max_parallel:]
        
        for item in initial_batch:
            future = executor.submit(process_script, item)
            future_to_idx[future] = item[0]
        
        # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬ ë° ìƒˆ ì‘ì—… ì œì¶œ
        while future_to_idx:
            # ì™„ë£Œëœ ì‘ì—… í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
            done, _ = concurrent.futures.wait(
                future_to_idx, 
                return_when=concurrent.futures.FIRST_COMPLETED
            )
            
            for future in done:
                try:
                    result = future.result()
                    results.append(result)
                    
                    # ìƒˆ ì‘ì—… ì œì¶œ (ë‚¨ì€ í•­ëª©ì´ ìˆëŠ” ê²½ìš°)
                    if remaining_items:
                        new_item = remaining_items.pop(0)
                        new_future = executor.submit(process_script, new_item)
                        future_to_idx[new_future] = new_item[0]
                    
                except Exception as e:
                    logger.error(f"âŒ TTS ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                    results.append((future_to_idx[future], "", False))
                
                # ì²˜ë¦¬ëœ future ì‚­ì œ
                del future_to_idx[future]
    
    # ê²°ê³¼ ì •ë ¬ (ì›ë˜ ìˆœì„œëŒ€ë¡œ)
    results.sort(key=lambda x: x[0])
    
    # ì„±ê³µí•œ ê²½ë¡œë§Œ í•„í„°ë§
    successful_paths = [res[1] for res in results if res[2]]
    
    success_count = len(successful_paths)
    logger.info(f"ğŸ TTS ìƒì„± ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {total_scripts - success_count}ê°œ")
    
    return successful_paths

def get_audio_info(audio_path: str) -> Dict[str, Any]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì˜¤ë””ì˜¤ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    info = {
        "duration": None,
        "format": None,
        "channels": None,
        "sample_rate": None,
        "bit_rate": None,
        "file_size": None
    }
    
    # íŒŒì¼ í¬ê¸°
    try:
        info["file_size"] = os.path.getsize(audio_path)
    except:
        pass
    
    # pydubìœ¼ë¡œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    try:
        from pydub import AudioSegment
        audio = AudioSegment.from_file(audio_path)
        info["duration"] = audio.duration_seconds
        info["channels"] = audio.channels
        info["sample_rate"] = audio.frame_rate
        info["format"] = Path(audio_path).suffix.lstrip('.')
        return info
    except:
        pass
    
    # mutagenìœ¼ë¡œ ì‹œë„
    try:
        from mutagen.mp3 import MP3
        audio = MP3(audio_path)
        info["duration"] = audio.info.length
        info["sample_rate"] = audio.info.sample_rate
        info["bit_rate"] = audio.info.bitrate
        info["format"] = "mp3"
        return info
    except:
        pass
    
    # ffprobeë¡œ ì‹œë„
    try:
        import subprocess
        import json
        cmd = [
            "ffprobe", "-v", "quiet", "-print_format", "json",
            "-show_format", "-show_streams", audio_path
        ]
        output = subprocess.check_output(cmd).decode('utf-8')
        data = json.loads(output)
        
        if "format" in data:
            fmt = data["format"]
            info["format"] = fmt.get("format_name")
            info["duration"] = float(fmt.get("duration", 0))
            info["bit_rate"] = int(fmt.get("bit_rate", 0))
        
        if "streams" in data and data["streams"]:
            stream = data["streams"][0]
            info["channels"] = stream.get("channels")
            info["sample_rate"] = int(stream.get("sample_rate", 0))
        
        return info
    except:
        pass
    
    return info

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    test_script = """
    The recent developments in Eastern Europe have significantly altered the strategic landscape of the region.
    [Video: Map of Eastern Europe with highlighted borders]
    
    Military analysts at the RAND Corporation suggest that this shift could impact NATO's defensive posture along its eastern flank.
    """
    
    logger.info("ğŸ“‹ Eleven Labs ì¶”ì²œ ìŒì„± ëª©ë¡:")
    recommended_voices = list_recommended_voices()
    for i, (name, voice_id, desc) in enumerate(recommended_voices):
        logger.info(f"{i+1}. {name}: {desc}")
    
    if api_key:
        logger.info("\nğŸ”Š í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¡œ TTS ìƒì„± ì¤‘...")
        voice_id = "pqHfZKP75CvOlQylNhV4"  # Bill ìŒì„± ì‚¬ìš©
        output_path = generate_tts_elevenlabs(test_script, voice_id=voice_id)
        if output_path:
            logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {output_path}")
            
            # ì˜¤ë””ì˜¤ ì •ë³´ ì¶œë ¥
            audio_info = get_audio_info(output_path)
            logger.info(f"ğŸ“Š ì˜¤ë””ì˜¤ ì •ë³´: ê¸¸ì´ {audio_info['duration']:.1f}ì´ˆ, í¬ê¸° {audio_info['file_size']/1024:.1f} KB")
        else:
            logger.error("âŒ TTS ìƒì„± ì‹¤íŒ¨")
    else:
        logger.warning("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")